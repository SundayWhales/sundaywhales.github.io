{"meta":{"version":1,"warehouse":"2.2.0"},"models":{"Asset":[{"_id":"themes/clean-blog/source/css/article.styl","path":"css/article.styl","modified":0,"renderable":1},{"_id":"themes/clean-blog/source/css/base.styl","path":"css/base.styl","modified":0,"renderable":1},{"_id":"themes/clean-blog/source/css/style.styl","path":"css/style.styl","modified":0,"renderable":1},{"_id":"themes/clean-blog/source/css/mixins.styl","path":"css/mixins.styl","modified":0,"renderable":1},{"_id":"themes/clean-blog/source/css/variables.styl","path":"css/variables.styl","modified":0,"renderable":1},{"_id":"themes/clean-blog/source/img/about-bg.jpg","path":"img/about-bg.jpg","modified":0,"renderable":1},{"_id":"themes/clean-blog/source/img/home-bg.jpg","path":"img/home-bg.jpg","modified":0,"renderable":1},{"_id":"themes/clean-blog/source/img/contact-bg.jpg","path":"img/contact-bg.jpg","modified":0,"renderable":1}],"Cache":[{"_id":"themes/clean-blog/LICENSE","hash":"8726b416df4f067cff579e859f05c4b594b8be09","modified":1513493758733},{"_id":"themes/clean-blog/README.md","hash":"861dd2f959ab75d121226f4f3e2f61f4bc95fddb","modified":1513493758733},{"_id":"themes/clean-blog/_config.yml","hash":"f193914278e28e4de5b550276bce18568c6e8b0f","modified":1513493895580},{"_id":"source/categories/index.md","hash":"c7e78f1545a7b25fb9debcf4a8cd8462e3e95d4d","modified":1513494398682},{"_id":"source/tags/index.md","hash":"6def6d68a5f7c6c4a04e73190bcf4dfaf3ad9ee7","modified":1513494352310},{"_id":"themes/clean-blog/.git/HEAD","hash":"acbaef275e46a7f14c1ef456fff2c8bbe8c84724","modified":1513493758723},{"_id":"source/_posts/hello-world.md","hash":"8a02477044e2b77f1b262da2c48c01429e4a32e4","modified":1513493714780},{"_id":"themes/clean-blog/.git/config","hash":"0037ed70f19e4933b19020ad514d8e9e049174f1","modified":1513493758726},{"_id":"themes/clean-blog/.git/description","hash":"9635f1b7e12c045212819dd934d809ef07efa2f4","modified":1513493753767},{"_id":"themes/clean-blog/.git/index","hash":"8cc4246e7868eeea6a68f2e27b26856a1b00bbc3","modified":1513493758747},{"_id":"themes/clean-blog/.git/packed-refs","hash":"78749f2f1de403b00552d862f076d37586b9b819","modified":1513493758720},{"_id":"themes/clean-blog/languages/de.yml","hash":"424a9c1e6ab69334d7873f6574da02ca960aa572","modified":1513493758734},{"_id":"themes/clean-blog/languages/default.yml","hash":"97326c9e6518d9f379778178b3b8f9a58434725d","modified":1513493758734},{"_id":"themes/clean-blog/languages/en.yml","hash":"97326c9e6518d9f379778178b3b8f9a58434725d","modified":1513493758734},{"_id":"themes/clean-blog/languages/es.yml","hash":"cb4eeca0ed3768a77e0cd216300f2b2549628b1b","modified":1513493758734},{"_id":"themes/clean-blog/languages/no.yml","hash":"8ca475a3b4f8efe6603030f0013aae39668230e1","modified":1513493758735},{"_id":"themes/clean-blog/languages/fr.yml","hash":"e9e6f7cb362ebb7997f11027498a2748fe3bac95","modified":1513493758734},{"_id":"themes/clean-blog/languages/pl.yml","hash":"de7eb5850ae65ba7638e907c805fea90617a988c","modified":1513493758735},{"_id":"themes/clean-blog/languages/pt.yml","hash":"1d0c3689eb32fe13f37f8f6f303af7624ebfbaf0","modified":1513493758735},{"_id":"themes/clean-blog/languages/ru.yml","hash":"42df7afeb7a35dc46d272b7f4fb880a9d9ebcaa5","modified":1513493758735},{"_id":"themes/clean-blog/languages/zh-CN.yml","hash":"7bfcb0b8e97d7e5edcfca8ab26d55d9da2573c1c","modified":1513493758736},{"_id":"themes/clean-blog/languages/zh-TW.yml","hash":"9acac6cc4f8002c3fa53ff69fb8cf66c915bd016","modified":1513493758736},{"_id":"themes/clean-blog/layout/archive.ejs","hash":"f2ef73afc3d275333329bb30b9369b82e119da76","modified":1513493758740},{"_id":"themes/clean-blog/layout/index.ejs","hash":"87995288ca6f95a04add641727aedd3f6afa55eb","modified":1513493758740},{"_id":"themes/clean-blog/layout/layout.ejs","hash":"da2f9018047924ddaf376aee5996c7ddc06cebc1","modified":1513493758741},{"_id":"themes/clean-blog/layout/page.ejs","hash":"591af587e1aae962950de7e79bd25c1f060c69ac","modified":1513493758741},{"_id":"themes/clean-blog/layout/post.ejs","hash":"38382e9bbeb6b8d2eafbd53fff2984111f524c1a","modified":1513493758741},{"_id":"themes/clean-blog/.git/hooks/applypatch-msg.sample","hash":"4de88eb95a5e93fd27e78b5fb3b5231a8d8917dd","modified":1513493753769},{"_id":"themes/clean-blog/.git/hooks/post-update.sample","hash":"b614c2f63da7dca9f1db2e7ade61ef30448fc96c","modified":1513493753769},{"_id":"themes/clean-blog/.git/hooks/commit-msg.sample","hash":"ee1ed5aad98a435f2020b6de35c173b75d9affac","modified":1513493753767},{"_id":"themes/clean-blog/.git/hooks/pre-applypatch.sample","hash":"f208287c1a92525de9f5462e905a9d31de1e2d75","modified":1513493753770},{"_id":"themes/clean-blog/.git/hooks/pre-push.sample","hash":"5c8518bfd1d1d3d2c1a7194994c0a16d8a313a41","modified":1513493753770},{"_id":"themes/clean-blog/.git/hooks/pre-commit.sample","hash":"36aed8976dcc08b5076844f0ec645b18bc37758f","modified":1513493753768},{"_id":"themes/clean-blog/.git/hooks/pre-rebase.sample","hash":"5885a56ab4fca8075a05a562d005e922cde9853b","modified":1513493753768},{"_id":"themes/clean-blog/.git/hooks/prepare-commit-msg.sample","hash":"2b6275eda365cad50d167fe3a387c9bc9fedd54f","modified":1513493753769},{"_id":"themes/clean-blog/.git/hooks/update.sample","hash":"39355a075977d05708ef74e1b66d09a36e486df1","modified":1513493753771},{"_id":"themes/clean-blog/.git/logs/HEAD","hash":"596af90a389344f5a7494dfce07f3e604822d2b3","modified":1513493758725},{"_id":"themes/clean-blog/.git/info/exclude","hash":"bb5a85730dcf100facee799c05cc4f6affec0745","modified":1513493753766},{"_id":"themes/clean-blog/layout/_partial/after-footer.ejs","hash":"80970a6cfbf9b1abe0c472636b321a9be08fdc43","modified":1513493758736},{"_id":"themes/clean-blog/layout/_partial/article-archive.ejs","hash":"3d8d98c6545b8332a6d6ed4f8b00327df03ea945","modified":1513493758736},{"_id":"themes/clean-blog/layout/_partial/article-categories.ejs","hash":"5a0bf5a20f670621d8013c9b9d7976b45c8aa80f","modified":1513493758737},{"_id":"themes/clean-blog/layout/_partial/article-full.ejs","hash":"0e7aa9da47f29b2312d9d3165c067576ebca77cf","modified":1513493758737},{"_id":"themes/clean-blog/layout/_partial/article-index.ejs","hash":"e433df4e245e2d4c628052c6e59966563542d94d","modified":1513493758737},{"_id":"themes/clean-blog/layout/_partial/article-tags.ejs","hash":"6136434be09056c1466149cecb3cc2e80d107999","modified":1513493758737},{"_id":"themes/clean-blog/layout/_partial/comments.ejs","hash":"3fedb75436439d1d6979b7e4d20d48a593e12be4","modified":1513493758738},{"_id":"themes/clean-blog/layout/_partial/gallery.ejs","hash":"21e4f28909f4a79ff7d9f10bdfef6a8cb11632bf","modified":1513493758738},{"_id":"themes/clean-blog/layout/_partial/google-analytics.ejs","hash":"4e6e8de9becea5a1636a4dcadcf7a10c06e2426e","modified":1513493758738},{"_id":"themes/clean-blog/layout/_partial/footer.ejs","hash":"d252fb1a41890e6481bb054f9cc4ceec3c0b0ed9","modified":1513493758738},{"_id":"themes/clean-blog/layout/_partial/head.ejs","hash":"3a7eb32f2cc540746c9e11010a4513b832743d1e","modified":1513493758739},{"_id":"themes/clean-blog/layout/_partial/menu.ejs","hash":"ba299316400499e9ede154e9627cafb7ce411888","modified":1513493758739},{"_id":"themes/clean-blog/layout/_partial/pagination.ejs","hash":"557d6bb069a1d48af49ae912994653f44b32a570","modified":1513493758740},{"_id":"themes/clean-blog/layout/_partial/tag-category-index.ejs","hash":"10cdc1b7866999c714a666557c150d2c79c1fba9","modified":1513493758740},{"_id":"themes/clean-blog/source/css/article.styl","hash":"f5294d7a3d6127fcb287de3ff0c12aebb1766c7b","modified":1513493758742},{"_id":"themes/clean-blog/source/css/base.styl","hash":"f0a6fcf58fe515e1359acde0ed34081f580ec7a3","modified":1513493758742},{"_id":"themes/clean-blog/source/css/style.styl","hash":"c40dc495a41007d21c59f342ee42b2d31d7b5ff4","modified":1513493758742},{"_id":"themes/clean-blog/source/css/mixins.styl","hash":"892f55e8a71f2e23a52e48e217dad3303bbad913","modified":1513493758742},{"_id":"themes/clean-blog/source/css/variables.styl","hash":"cd82df5ca8dfbcfec12d833f01adfac00878e835","modified":1513493758743},{"_id":"themes/clean-blog/source/img/about-bg.jpg","hash":"d39126a6456f2bac0169d1779304725f179c9900","modified":1513493758743},{"_id":"themes/clean-blog/.git/refs/heads/master","hash":"0f3b4e362de29ccd7fa4b5983e9a0ea546623577","modified":1513493758724},{"_id":"themes/clean-blog/.git/objects/pack/pack-e40396fae3380f0083541840f14cd6b4b7d45b66.idx","hash":"da03f243d920e8c54c8d71a31bafe36fe8c75a62","modified":1513493758709},{"_id":"themes/clean-blog/source/img/home-bg.jpg","hash":"990f6f9dd0ecb5348bfcc47305553d58c0d8f326","modified":1513493758746},{"_id":"themes/clean-blog/.git/logs/refs/heads/master","hash":"596af90a389344f5a7494dfce07f3e604822d2b3","modified":1513493758725},{"_id":"themes/clean-blog/.git/refs/remotes/origin/HEAD","hash":"d9427cda09aba1cdde5c69c2b13c905bddb0bc51","modified":1513493758721},{"_id":"themes/clean-blog/source/img/contact-bg.jpg","hash":"6af63305c923899017e727b5ca968a2703bc08cf","modified":1513493758745},{"_id":"themes/clean-blog/.git/logs/refs/remotes/origin/HEAD","hash":"596af90a389344f5a7494dfce07f3e604822d2b3","modified":1513493758722},{"_id":"themes/clean-blog/.git/objects/pack/pack-e40396fae3380f0083541840f14cd6b4b7d45b66.pack","hash":"c61285061fe0dfd9a9048a88cbc4f5b21b022682","modified":1513493758709},{"_id":"source/_posts/kops.md","hash":"3227a121a34480efeee86d4c59751e3a649872ee","modified":1513495044900},{"_id":"public/categories/index.html","hash":"102daa97e6f71c97582872e447608fa50e201cab","modified":1513495075861},{"_id":"public/tags/index.html","hash":"414c4226fdf4b6fc54ced7fa069bf6bd20776631","modified":1513495075867},{"_id":"public/2017/12/17/hello-world/index.html","hash":"0b8999d1ce580deeb0226a58a12fb27dc0be2e4b","modified":1513495075868},{"_id":"public/archives/index.html","hash":"024e5568d0127a1006f49da59a0b015b3e83f0aa","modified":1513495075868},{"_id":"public/archives/2017/index.html","hash":"94327157c634887d9d0773645dfaa7b26a689132","modified":1513495075868},{"_id":"public/archives/2017/12/index.html","hash":"2efb9ccac6a52fe49300d8e95f36f4314e38c3dd","modified":1513495075868},{"_id":"public/categories/k8s/index.html","hash":"0423552da246f17f6e4db52580232218f268a498","modified":1513495075868},{"_id":"public/index.html","hash":"de182cf20d8b2a48c49e1c3bb32f956776bc5cdd","modified":1513495075868},{"_id":"public/tags/k8s/index.html","hash":"7b21da8473e92d5ee91bfdadc4a74bcec73e34b6","modified":1513495075868},{"_id":"public/2017/12/17/kops/index.html","hash":"55c147ca3e18761afd294343a2cf341d1b1d43c8","modified":1513495075868},{"_id":"public/tags/kubernetes/index.html","hash":"18ca5bb9eba0f808f5914c517a7e082dc33b11f5","modified":1513495075870},{"_id":"public/tags/docker/index.html","hash":"6ad45855415ddec664cba451c4ff3c800a99b4ce","modified":1513495075870}],"Category":[{"name":"k8s","_id":"cjbafmu3g000337ohy2hbt10b"}],"Data":[],"Page":[{"title":"All categories","type":"categories","_content":"","source":"categories/index.md","raw":"---\ntitle: All categories\ntype: \"categories\"\n---","date":"2017-12-17T07:06:38.682Z","updated":"2017-12-17T07:06:38.682Z","path":"categories/index.html","_id":"cjbafgtx30000msohwianu14i","comments":1,"layout":"page","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"All tags","type":"tags","_content":"","source":"tags/index.md","raw":"---\ntitle: All tags\ntype: \"tags\"\n---","date":"2017-12-17T07:05:52.310Z","updated":"2017-12-17T07:05:52.310Z","path":"tags/index.html","comments":1,"layout":"page","_id":"cjbafgtx90002msoh8agvg4ij","content":"","site":{"data":{}},"excerpt":"","more":""}],"Post":[{"title":"Hello World","_content":"Welcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).\n\n## Quick Start\n\n### Create a new post\n\n``` bash\n$ hexo new \"My New Post\"\n```\n\nMore info: [Writing](https://hexo.io/docs/writing.html)\n\n### Run server\n\n``` bash\n$ hexo server\n```\n\nMore info: [Server](https://hexo.io/docs/server.html)\n\n### Generate static files\n\n``` bash\n$ hexo generate\n```\n\nMore info: [Generating](https://hexo.io/docs/generating.html)\n\n### Deploy to remote sites\n\n``` bash\n$ hexo deploy\n```\n\nMore info: [Deployment](https://hexo.io/docs/deployment.html)\n","source":"_posts/hello-world.md","raw":"---\ntitle: Hello World\n---\nWelcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).\n\n## Quick Start\n\n### Create a new post\n\n``` bash\n$ hexo new \"My New Post\"\n```\n\nMore info: [Writing](https://hexo.io/docs/writing.html)\n\n### Run server\n\n``` bash\n$ hexo server\n```\n\nMore info: [Server](https://hexo.io/docs/server.html)\n\n### Generate static files\n\n``` bash\n$ hexo generate\n```\n\nMore info: [Generating](https://hexo.io/docs/generating.html)\n\n### Deploy to remote sites\n\n``` bash\n$ hexo deploy\n```\n\nMore info: [Deployment](https://hexo.io/docs/deployment.html)\n","slug":"hello-world","published":1,"date":"2017-12-17T06:55:14.780Z","updated":"2017-12-17T06:55:14.780Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjbafgtx50001msoh6dmlckaz","content":"<p>Welcome to <a href=\"https://hexo.io/\" target=\"_blank\" rel=\"noopener\">Hexo</a>! This is your very first post. Check <a href=\"https://hexo.io/docs/\" target=\"_blank\" rel=\"noopener\">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href=\"https://hexo.io/docs/troubleshooting.html\" target=\"_blank\" rel=\"noopener\">troubleshooting</a> or you can ask me on <a href=\"https://github.com/hexojs/hexo/issues\" target=\"_blank\" rel=\"noopener\">GitHub</a>.</p>\n<h2 id=\"Quick-Start\"><a href=\"#Quick-Start\" class=\"headerlink\" title=\"Quick Start\"></a>Quick Start</h2><h3 id=\"Create-a-new-post\"><a href=\"#Create-a-new-post\" class=\"headerlink\" title=\"Create a new post\"></a>Create a new post</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo new <span class=\"string\">\"My New Post\"</span></span><br></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/writing.html\" target=\"_blank\" rel=\"noopener\">Writing</a></p>\n<h3 id=\"Run-server\"><a href=\"#Run-server\" class=\"headerlink\" title=\"Run server\"></a>Run server</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo server</span><br></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/server.html\" target=\"_blank\" rel=\"noopener\">Server</a></p>\n<h3 id=\"Generate-static-files\"><a href=\"#Generate-static-files\" class=\"headerlink\" title=\"Generate static files\"></a>Generate static files</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo generate</span><br></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/generating.html\" target=\"_blank\" rel=\"noopener\">Generating</a></p>\n<h3 id=\"Deploy-to-remote-sites\"><a href=\"#Deploy-to-remote-sites\" class=\"headerlink\" title=\"Deploy to remote sites\"></a>Deploy to remote sites</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo deploy</span><br></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/deployment.html\" target=\"_blank\" rel=\"noopener\">Deployment</a></p>\n","site":{"data":{}},"excerpt":"","more":"<p>Welcome to <a href=\"https://hexo.io/\" target=\"_blank\" rel=\"noopener\">Hexo</a>! This is your very first post. Check <a href=\"https://hexo.io/docs/\" target=\"_blank\" rel=\"noopener\">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href=\"https://hexo.io/docs/troubleshooting.html\" target=\"_blank\" rel=\"noopener\">troubleshooting</a> or you can ask me on <a href=\"https://github.com/hexojs/hexo/issues\" target=\"_blank\" rel=\"noopener\">GitHub</a>.</p>\n<h2 id=\"Quick-Start\"><a href=\"#Quick-Start\" class=\"headerlink\" title=\"Quick Start\"></a>Quick Start</h2><h3 id=\"Create-a-new-post\"><a href=\"#Create-a-new-post\" class=\"headerlink\" title=\"Create a new post\"></a>Create a new post</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo new <span class=\"string\">\"My New Post\"</span></span><br></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/writing.html\" target=\"_blank\" rel=\"noopener\">Writing</a></p>\n<h3 id=\"Run-server\"><a href=\"#Run-server\" class=\"headerlink\" title=\"Run server\"></a>Run server</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo server</span><br></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/server.html\" target=\"_blank\" rel=\"noopener\">Server</a></p>\n<h3 id=\"Generate-static-files\"><a href=\"#Generate-static-files\" class=\"headerlink\" title=\"Generate static files\"></a>Generate static files</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo generate</span><br></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/generating.html\" target=\"_blank\" rel=\"noopener\">Generating</a></p>\n<h3 id=\"Deploy-to-remote-sites\"><a href=\"#Deploy-to-remote-sites\" class=\"headerlink\" title=\"Deploy to remote sites\"></a>Deploy to remote sites</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo deploy</span><br></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/deployment.html\" target=\"_blank\" rel=\"noopener\">Deployment</a></p>\n"},{"title":"kops","date":"2017-12-17T07:08:58.000Z","_content":"\n<p align=\"center\">\n  <img src=\"img/k8s-aws.png\"> </image>\n</p>\n\n# Getting Started\n\n## Install kops\n\nBefore we can bring up the cluster we need to [install the CLI tool](install.md) `kops`.\n\n## Install kubectl\n\nIn order to control Kubernetes clusters we need to [install the CLI tool](install.md) `kubectl`.\n\n#### Other Platforms\n\n* [Kubernetes Latest Release](https://github.com/kubernetes/kubernetes/releases/latest)\n\n* [Installation Guide](http://kubernetes.io/docs/user-guide/prereqs/)\n\n## Setup your environment\n\n### AWS\n\nIn order to correctly prepare your AWS account for `kops`, we require you to\ninstall the AWS CLI tools, and have API credentials for an account that has\nthe permissions to create a new IAM account for `kops` later in the guide.\n\n\nOnce you've [installed the AWS CLI tools](install.md) and have correctly setup\nyour system to use the official AWS methods of registering security credentials\nas [defined here](https://docs.aws.amazon.com/sdk-for-go/v1/developer-guide/configuring-sdk.html#specifying-credentials) we'll be ready to run `kops`, as it uses the Go AWS SDK.\n\n#### Setup IAM user\n\nIn order to build clusters within AWS we'll create a dedicated IAM user for\n`kops`.  This user requires API credentials in order to use `kops`.  Create\nthe user, and credentials, using the [AWS console](http://docs.aws.amazon.com/IAM/latest/UserGuide/id_users_create.html#id_users_create_console).\n\nThe `kops` user will require the following IAM permissions to function properly:\n\n```\nAmazonEC2FullAccess\nAmazonRoute53FullAccess\nAmazonS3FullAccess\nIAMFullAccess\nAmazonVPCFullAccess\n```\n\nYou can create the kops IAM user from the command line using the following:\n\n```bash\naws iam create-group --group-name kops\n\naws iam attach-group-policy --policy-arn arn:aws:iam::aws:policy/AmazonEC2FullAccess --group-name kops\naws iam attach-group-policy --policy-arn arn:aws:iam::aws:policy/AmazonRoute53FullAccess --group-name kops\naws iam attach-group-policy --policy-arn arn:aws:iam::aws:policy/AmazonS3FullAccess --group-name kops\naws iam attach-group-policy --policy-arn arn:aws:iam::aws:policy/IAMFullAccess --group-name kops\naws iam attach-group-policy --policy-arn arn:aws:iam::aws:policy/AmazonVPCFullAccess --group-name kops\n\naws iam create-user --user-name kops\n\naws iam add-user-to-group --user-name kops --group-name kops\n\naws iam create-access-key --user-name kops\n```\n\nYou should record the SecretAccessKey and AccessKeyID in the returned JSON\noutput, and then use them below:\n\n```bash\n# configure the aws client to use your new IAM user\naws configure           # Use your new access and secret key here\naws iam list-users      # you should see a list of all your IAM users here\n\n# Because \"aws configure\" doesn't export these vars for kops to use, we export them now\nexport AWS_ACCESS_KEY_ID=$(aws configure get aws_access_key_id)\nexport AWS_SECRET_ACCESS_KEY=$(aws configure get aws_secret_access_key)\n```\n\n## Configure DNS\n\nNote: If you are using Kops 1.6.2 or later, then DNS configuration is\noptional. Instead, a gossip-based cluster can be easily created. The\nonly requirement to trigger this is to have the cluster name end with\n`.k8s.local`. If a gossip-based cluster is created then you can skip\nthis section.\n\nIn order to build a Kubernetes cluster with `kops`, we need to prepare\nsomewhere to build the required DNS records.  There are three scenarios\nbelow and you should choose the one that most closely matches your AWS\nsituation.\n\n### Scenario 1a: A Domain purchased/hosted via AWS\n\nIf you bought your domain with AWS, then you should already have a hosted zone\nin Route53.  If you plan to use this domain then no more work is needed.\n\nIn this example you own `example.com` and your records for Kubernetes would\nlook like `etcd-us-east-1c.internal.clustername.example.com`\n\n### Scenario 1b: A subdomain under a domain purchased/hosted via AWS\n\nIn this scenario you want to contain all kubernetes records under a subdomain\nof a domain you host in Route53.  This requires creating a second hosted zone\nin route53, and then setting up route delegation to the new zone.\n\nIn this example you own `example.com` and your records for Kubernetes would\nlook like `etcd-us-east-1c.internal.clustername.subdomain.example.com`\n\nThis is copying the NS servers of your **SUBDOMAIN** up to the **PARENT**\ndomain in Route53.  To do this you should:\n\n* Create the subdomain, and note your **SUBDOMAIN** name servers (If you have\n  already done this you can also [get the values](ns.md))\n\n```bash\n# Note: This example assumes you have jq installed locally.\nID=$(uuidgen) && aws route53 create-hosted-zone --name subdomain.example.com --caller-reference $ID | \\\n    jq .DelegationSet.NameServers\n```\n\n* Note your **PARENT** hosted zone id\n\n```bash\n# Note: This example assumes you have jq installed locally.\naws route53 list-hosted-zones | jq '.HostedZones[] | select(.Name==\"example.com.\") | .Id'\n```\n\n* Create a new JSON file with your values (`subdomain.json`)\n\nNote: The NS values here are for the **SUBDOMAIN**\n\n```\n{\n  \"Comment\": \"Create a subdomain NS record in the parent domain\",\n  \"Changes\": [\n    {\n      \"Action\": \"CREATE\",\n      \"ResourceRecordSet\": {\n        \"Name\": \"subdomain.example.com\",\n        \"Type\": \"NS\",\n        \"TTL\": 300,\n        \"ResourceRecords\": [\n          {\n            \"Value\": \"ns-1.awsdns-1.co.uk\"\n          },\n          {\n            \"Value\": \"ns-2.awsdns-2.org\"\n          },\n          {\n            \"Value\": \"ns-3.awsdns-3.com\"\n          },\n          {\n            \"Value\": \"ns-4.awsdns-4.net\"\n          }\n        ]\n      }\n    }\n  ]\n}\n```\n\n* Apply the **SUBDOMAIN** NS records to the **PARENT** hosted zone.\n\n```\naws route53 change-resource-record-sets \\\n --hosted-zone-id <parent-zone-id> \\\n --change-batch file://subdomain.json\n```\n\nNow traffic to `*.subdomain.example.com` will be routed to the correct subdomain hosted zone in Route53.\n\n### Scenario 2: Setting up Route53 for a domain purchased with another registrar\n\nIf you bought your domain elsewhere, and would like to dedicate the entire domain to AWS you should follow the guide [here](http://docs.aws.amazon.com/Route53/latest/DeveloperGuide/domain-transfer-to-route-53.html)\n\n### Scenario 3: Subdomain for clusters in route53, leaving the domain at another registrar\n\nIf you bought your domain elsewhere, but **only want to use a subdomain in AWS\nRoute53** you must modify your registrar's NS (NameServer) records.  We'll create\na hosted zone in Route53, and then migrate the subdomain's NS records to your\nother registrar.\n\nYou might need to grab [jq](https://github.com/stedolan/jq/wiki/Installation)\nfor some of these instructions.\n\n* Create the subdomain, and note your name servers (If you have already done\n  this you can also [get the values](ns.md))\n\n```bash\nID=$(uuidgen) && aws route53 create-hosted-zone --name subdomain.example.com --caller-reference $ID | jq .DelegationSet.NameServers\n```\n\n* You will now go to your registrar's page and log in. You will need to create a\n  new **SUBDOMAIN**, and use the 4 NS records received from the above command for the new\n  **SUBDOMAIN**. This **MUST** be done in order to use your cluster. Do **NOT**\n  change your top level NS record, or you might take your site offline.\n\n* Information on adding NS records with\n  [Godaddy.com](https://www.godaddy.com/help/set-custom-nameservers-for-domains-registered-with-godaddy-12317)\n* Information on adding NS records with [Google Cloud\n  Platform](https://cloud.google.com/dns/update-name-servers)\n\n#### Using Public/Private DNS (Kops 1.5+)\n\nBy default the assumption is that NS records are publically available.  If you\nrequire private DNS records you should modify the commands we run later in this\nguide to include:\n\n```\nkops create cluster --dns private $NAME\n```\n\nIf you have a mix of public and private zones, you will also need to include the `--dns-zone` argument with the hosted zone id you wish to deploy in:\n\n```\nkops create cluster --dns private --dns-zone ZABCDEFG $NAME\n```\n\n## Testing your DNS setup\n\nThis section is not be required if a gossip-based cluster is created.\n\nYou should now able to dig your domain (or subdomain) and see the AWS Name\nServers on the other end.\n\n```bash\ndig ns subdomain.example.com\n```\n\nShould return something similar to:\n\n```\n;; ANSWER SECTION:\nsubdomain.example.com.        172800  IN  NS  ns-1.awsdns-1.net.\nsubdomain.example.com.        172800  IN  NS  ns-2.awsdns-2.org.\nsubdomain.example.com.        172800  IN  NS  ns-3.awsdns-3.com.\nsubdomain.example.com.        172800  IN  NS  ns-4.awsdns-4.co.uk.\n```\n\nThis is a critical component of setting up clusters. If you are experiencing\nproblems with the Kubernetes API not coming up, chances are something is wrong\nwith the cluster's DNS.\n\n**Please DO NOT MOVE ON until you have validated your NS records! This is not be required if a gossip-based cluster is created.**\n\n## Cluster State storage\n\nIn order to store the state of your cluster, and the representation of your\ncluster, we need to create a dedicated S3 bucket for `kops` to use.  This\nbucket will become the source of truth for our cluster configuration.  In\nthis guide we'll call this bucket `example-com-state-store`, but you should\nadd a custom prefix as bucket names need to be unique.\n\nWe recommend keeping the creation of this bucket confined to us-east-1,\notherwise more work will be required.\n\n```bash\naws s3api create-bucket \\\n    --bucket prefix-example-com-state-store \\\n    --region us-east-1\n```\n\nNote: S3 requires `--create-bucket-configuration LocationConstraint=<region>` for regions other than `us-east-1`.\n\nNote: We **STRONGLY** recommend versioning your S3 bucket in case you ever need\nto revert or recover a previous state store.\n\n```bash\naws s3api put-bucket-versioning --bucket prefix-example-com-state-store  --versioning-configuration Status=Enabled\n```\n\n### Sharing an S3 bucket across multiple accounts\n\nIt is possible to use a single S3 bucket for storing kops state for clusters\nlocated in different accounts, by using [cross-account bucket policies](http://docs.aws.amazon.com/AmazonS3/latest/dev/example-walkthroughs-managing-access-example2.html#access-policies-walkthrough-cross-account-permissions-acctA-tasks).\n\nKops will be able to use buckets configured with cross-account policies by default.\n\nIn this case you may want to override the object ACLs which kops places on the\nstate files, as default AWS ACLs will make it possible for an account that has\ndelegated access to write files that the bucket owner can not read.\n\nTo do this you should set the environment variable `KOPS_STATE_S3_ACL` to the\npreferred object ACL, for example `bucket-owner-full-control`.\n\nFor available canned ACLs please consult [Amazon's S3\ndocumentation](http://docs.aws.amazon.com/AmazonS3/latest/dev/acl-overview.html#canned-acl).\n\n# Creating your first cluster\n\n## Prepare local environment\n\nWe're ready to start creating our first cluster!  Let's first set up a few\nenvironment variables to make this process easier.\n\n```bash\nexport NAME=myfirstcluster.example.com\nexport KOPS_STATE_STORE=s3://prefix-example-com-state-store\n```\n\nFor a gossip-based cluster, make sure the name ends with `k8s.local`. For example:\n\n```bash\nexport NAME=myfirstcluster.k8s.local\nexport KOPS_STATE_STORE=s3://prefix-example-com-state-store\n```\n\nNote: You don’t have to use environmental variables here. You can always define\nthe values using the –name and –state flags later.\n\n## Create cluster configuration\n\nWe will need to note which availability zones are available to us. In this\nexample we will be deploying our cluster to the us-west-2 region.\n\n```bash\naws ec2 describe-availability-zones --region us-west-2\n```\n\nBelow is a create cluster command.  We'll use the most basic example possible,\nwith more verbose examples in [high availability](high_availability.md#advanced-example).\nThe below command will generate a cluster configuration, but not start building\nit. Make sure that you have generated SSH key pair before creating the cluster.\n\n```bash\nkops create cluster \\\n    --zones us-west-2a \\\n    ${NAME}\n```\n\nAll instances created by `kops` will be built within ASG (Auto Scaling Groups),\nwhich means each instance will be automatically monitored and rebuilt by AWS if\nit suffers any failure.\n\n## Customize Cluster Configuration\n\nNow we have a cluster configuration, we can look at every aspect that defines\nour cluster by editing the description.\n\n```bash\nkops edit cluster ${NAME}\n```\n\nThis opens your editor (as defined by $EDITOR) and allows you to edit the\nconfiguration.  The configuration is loaded from the S3 bucket we created\nearlier, and automatically updated when we save and exit the editor.\n\nWe'll leave everything set to the defaults for now, but the rest of the `kops`\ndocumentation covers additional settings and configuration you can enable.\n\n## Build the Cluster\n\nNow we take the final step of actually building the cluster.  This'll take a\nwhile.  Once it finishes you'll have to wait longer while the booted instances\nfinish downloading Kubernetes components and reach a \"ready\" state.\n\n```bash\nkops update cluster ${NAME} --yes\n```\n\n## Use the Cluster\n\nRemember when you installed `kubectl` earlier? The configuration for your\ncluster was automatically generated and written to `~/.kube/config` for you!\n\nA simple Kubernetes API call can be used to check if the API is online and\nlistening. Let's use `kubectl` to check the nodes.\n\n```bash\nkubectl get nodes\n```\n\nYou will see a list of nodes that should match the `--zones` flag defined\nearlier. This is a great sign that your Kubernetes cluster is online and\nworking.\n\nAlso `kops` ships with a handy validation tool that can be ran to ensure your\ncluster is working as expected.\n\n```bash\nkops validate cluster\n```\n\nYou can look at all the system components with the following command.\n\n```\nkubectl -n kube-system get po\n```\n\n## Delete the Cluster\n\nRunning a Kubernetes cluster within AWS obviously costs money, and so you may\nwant to delete your cluster if you are finished running experiments.\n\nYou can preview all of the AWS resources that will be destroyed when the cluster\nis deleted by issuing the following command.\n\n```\nkops delete cluster --name ${NAME}\n```\n\nWhen you are sure you want to delete your cluster, issue the delete command\nwith the `--yes` flag. Note that this command is very destructive, and will\ndelete your cluster and everything contained within it!\n\n```\nkops delete cluster --name ${NAME} --yes\n```\n\n# What's next?\n\nWe've barely scratched the surface of the capabilities of `kops` in this guide,\nand we recommend researching [other interesting\nmodes](commands.md#other-interesting-modes) to learn more about generating\nTerraform configurations, or running your cluster in an HA (Highly Available)\nmode.\n\nThe [cluster spec docs](cluster_spec.md) can help to configure these \"other\ninteresting modes\". Also be sure to check out how to run a [private network\ntopology](topology.md) in AWS.\n\n## Feedback\n\nThere's an incredible team behind Kops and we encourage you to reach out to the\ncommunity on the Kubernetes\nSlack(http://slack.k8s.io/).  Bring your\nquestions, comments, and requests and meet the people behind the project!\n\n## Legal\n\n*AWS Trademark used with limited permission under the [AWS Trademark\nGuidelines](https://aws.amazon.com/trademark-guidelines/)*\n\n*Kubernetes Logo used with permission under the [Kubernetes Branding\nGuidelines](https://github.com/kubernetes/kubernetes/blob/master/logo/usage_guidelines.md)*","source":"_posts/kops.md","raw":"---\ntitle: kops\ndate: 2017-12-17 16:08:58\ntags: \n  - kubernetes\n  - k8s\n  - docker\ncategories: k8s\n---\n\n<p align=\"center\">\n  <img src=\"img/k8s-aws.png\"> </image>\n</p>\n\n# Getting Started\n\n## Install kops\n\nBefore we can bring up the cluster we need to [install the CLI tool](install.md) `kops`.\n\n## Install kubectl\n\nIn order to control Kubernetes clusters we need to [install the CLI tool](install.md) `kubectl`.\n\n#### Other Platforms\n\n* [Kubernetes Latest Release](https://github.com/kubernetes/kubernetes/releases/latest)\n\n* [Installation Guide](http://kubernetes.io/docs/user-guide/prereqs/)\n\n## Setup your environment\n\n### AWS\n\nIn order to correctly prepare your AWS account for `kops`, we require you to\ninstall the AWS CLI tools, and have API credentials for an account that has\nthe permissions to create a new IAM account for `kops` later in the guide.\n\n\nOnce you've [installed the AWS CLI tools](install.md) and have correctly setup\nyour system to use the official AWS methods of registering security credentials\nas [defined here](https://docs.aws.amazon.com/sdk-for-go/v1/developer-guide/configuring-sdk.html#specifying-credentials) we'll be ready to run `kops`, as it uses the Go AWS SDK.\n\n#### Setup IAM user\n\nIn order to build clusters within AWS we'll create a dedicated IAM user for\n`kops`.  This user requires API credentials in order to use `kops`.  Create\nthe user, and credentials, using the [AWS console](http://docs.aws.amazon.com/IAM/latest/UserGuide/id_users_create.html#id_users_create_console).\n\nThe `kops` user will require the following IAM permissions to function properly:\n\n```\nAmazonEC2FullAccess\nAmazonRoute53FullAccess\nAmazonS3FullAccess\nIAMFullAccess\nAmazonVPCFullAccess\n```\n\nYou can create the kops IAM user from the command line using the following:\n\n```bash\naws iam create-group --group-name kops\n\naws iam attach-group-policy --policy-arn arn:aws:iam::aws:policy/AmazonEC2FullAccess --group-name kops\naws iam attach-group-policy --policy-arn arn:aws:iam::aws:policy/AmazonRoute53FullAccess --group-name kops\naws iam attach-group-policy --policy-arn arn:aws:iam::aws:policy/AmazonS3FullAccess --group-name kops\naws iam attach-group-policy --policy-arn arn:aws:iam::aws:policy/IAMFullAccess --group-name kops\naws iam attach-group-policy --policy-arn arn:aws:iam::aws:policy/AmazonVPCFullAccess --group-name kops\n\naws iam create-user --user-name kops\n\naws iam add-user-to-group --user-name kops --group-name kops\n\naws iam create-access-key --user-name kops\n```\n\nYou should record the SecretAccessKey and AccessKeyID in the returned JSON\noutput, and then use them below:\n\n```bash\n# configure the aws client to use your new IAM user\naws configure           # Use your new access and secret key here\naws iam list-users      # you should see a list of all your IAM users here\n\n# Because \"aws configure\" doesn't export these vars for kops to use, we export them now\nexport AWS_ACCESS_KEY_ID=$(aws configure get aws_access_key_id)\nexport AWS_SECRET_ACCESS_KEY=$(aws configure get aws_secret_access_key)\n```\n\n## Configure DNS\n\nNote: If you are using Kops 1.6.2 or later, then DNS configuration is\noptional. Instead, a gossip-based cluster can be easily created. The\nonly requirement to trigger this is to have the cluster name end with\n`.k8s.local`. If a gossip-based cluster is created then you can skip\nthis section.\n\nIn order to build a Kubernetes cluster with `kops`, we need to prepare\nsomewhere to build the required DNS records.  There are three scenarios\nbelow and you should choose the one that most closely matches your AWS\nsituation.\n\n### Scenario 1a: A Domain purchased/hosted via AWS\n\nIf you bought your domain with AWS, then you should already have a hosted zone\nin Route53.  If you plan to use this domain then no more work is needed.\n\nIn this example you own `example.com` and your records for Kubernetes would\nlook like `etcd-us-east-1c.internal.clustername.example.com`\n\n### Scenario 1b: A subdomain under a domain purchased/hosted via AWS\n\nIn this scenario you want to contain all kubernetes records under a subdomain\nof a domain you host in Route53.  This requires creating a second hosted zone\nin route53, and then setting up route delegation to the new zone.\n\nIn this example you own `example.com` and your records for Kubernetes would\nlook like `etcd-us-east-1c.internal.clustername.subdomain.example.com`\n\nThis is copying the NS servers of your **SUBDOMAIN** up to the **PARENT**\ndomain in Route53.  To do this you should:\n\n* Create the subdomain, and note your **SUBDOMAIN** name servers (If you have\n  already done this you can also [get the values](ns.md))\n\n```bash\n# Note: This example assumes you have jq installed locally.\nID=$(uuidgen) && aws route53 create-hosted-zone --name subdomain.example.com --caller-reference $ID | \\\n    jq .DelegationSet.NameServers\n```\n\n* Note your **PARENT** hosted zone id\n\n```bash\n# Note: This example assumes you have jq installed locally.\naws route53 list-hosted-zones | jq '.HostedZones[] | select(.Name==\"example.com.\") | .Id'\n```\n\n* Create a new JSON file with your values (`subdomain.json`)\n\nNote: The NS values here are for the **SUBDOMAIN**\n\n```\n{\n  \"Comment\": \"Create a subdomain NS record in the parent domain\",\n  \"Changes\": [\n    {\n      \"Action\": \"CREATE\",\n      \"ResourceRecordSet\": {\n        \"Name\": \"subdomain.example.com\",\n        \"Type\": \"NS\",\n        \"TTL\": 300,\n        \"ResourceRecords\": [\n          {\n            \"Value\": \"ns-1.awsdns-1.co.uk\"\n          },\n          {\n            \"Value\": \"ns-2.awsdns-2.org\"\n          },\n          {\n            \"Value\": \"ns-3.awsdns-3.com\"\n          },\n          {\n            \"Value\": \"ns-4.awsdns-4.net\"\n          }\n        ]\n      }\n    }\n  ]\n}\n```\n\n* Apply the **SUBDOMAIN** NS records to the **PARENT** hosted zone.\n\n```\naws route53 change-resource-record-sets \\\n --hosted-zone-id <parent-zone-id> \\\n --change-batch file://subdomain.json\n```\n\nNow traffic to `*.subdomain.example.com` will be routed to the correct subdomain hosted zone in Route53.\n\n### Scenario 2: Setting up Route53 for a domain purchased with another registrar\n\nIf you bought your domain elsewhere, and would like to dedicate the entire domain to AWS you should follow the guide [here](http://docs.aws.amazon.com/Route53/latest/DeveloperGuide/domain-transfer-to-route-53.html)\n\n### Scenario 3: Subdomain for clusters in route53, leaving the domain at another registrar\n\nIf you bought your domain elsewhere, but **only want to use a subdomain in AWS\nRoute53** you must modify your registrar's NS (NameServer) records.  We'll create\na hosted zone in Route53, and then migrate the subdomain's NS records to your\nother registrar.\n\nYou might need to grab [jq](https://github.com/stedolan/jq/wiki/Installation)\nfor some of these instructions.\n\n* Create the subdomain, and note your name servers (If you have already done\n  this you can also [get the values](ns.md))\n\n```bash\nID=$(uuidgen) && aws route53 create-hosted-zone --name subdomain.example.com --caller-reference $ID | jq .DelegationSet.NameServers\n```\n\n* You will now go to your registrar's page and log in. You will need to create a\n  new **SUBDOMAIN**, and use the 4 NS records received from the above command for the new\n  **SUBDOMAIN**. This **MUST** be done in order to use your cluster. Do **NOT**\n  change your top level NS record, or you might take your site offline.\n\n* Information on adding NS records with\n  [Godaddy.com](https://www.godaddy.com/help/set-custom-nameservers-for-domains-registered-with-godaddy-12317)\n* Information on adding NS records with [Google Cloud\n  Platform](https://cloud.google.com/dns/update-name-servers)\n\n#### Using Public/Private DNS (Kops 1.5+)\n\nBy default the assumption is that NS records are publically available.  If you\nrequire private DNS records you should modify the commands we run later in this\nguide to include:\n\n```\nkops create cluster --dns private $NAME\n```\n\nIf you have a mix of public and private zones, you will also need to include the `--dns-zone` argument with the hosted zone id you wish to deploy in:\n\n```\nkops create cluster --dns private --dns-zone ZABCDEFG $NAME\n```\n\n## Testing your DNS setup\n\nThis section is not be required if a gossip-based cluster is created.\n\nYou should now able to dig your domain (or subdomain) and see the AWS Name\nServers on the other end.\n\n```bash\ndig ns subdomain.example.com\n```\n\nShould return something similar to:\n\n```\n;; ANSWER SECTION:\nsubdomain.example.com.        172800  IN  NS  ns-1.awsdns-1.net.\nsubdomain.example.com.        172800  IN  NS  ns-2.awsdns-2.org.\nsubdomain.example.com.        172800  IN  NS  ns-3.awsdns-3.com.\nsubdomain.example.com.        172800  IN  NS  ns-4.awsdns-4.co.uk.\n```\n\nThis is a critical component of setting up clusters. If you are experiencing\nproblems with the Kubernetes API not coming up, chances are something is wrong\nwith the cluster's DNS.\n\n**Please DO NOT MOVE ON until you have validated your NS records! This is not be required if a gossip-based cluster is created.**\n\n## Cluster State storage\n\nIn order to store the state of your cluster, and the representation of your\ncluster, we need to create a dedicated S3 bucket for `kops` to use.  This\nbucket will become the source of truth for our cluster configuration.  In\nthis guide we'll call this bucket `example-com-state-store`, but you should\nadd a custom prefix as bucket names need to be unique.\n\nWe recommend keeping the creation of this bucket confined to us-east-1,\notherwise more work will be required.\n\n```bash\naws s3api create-bucket \\\n    --bucket prefix-example-com-state-store \\\n    --region us-east-1\n```\n\nNote: S3 requires `--create-bucket-configuration LocationConstraint=<region>` for regions other than `us-east-1`.\n\nNote: We **STRONGLY** recommend versioning your S3 bucket in case you ever need\nto revert or recover a previous state store.\n\n```bash\naws s3api put-bucket-versioning --bucket prefix-example-com-state-store  --versioning-configuration Status=Enabled\n```\n\n### Sharing an S3 bucket across multiple accounts\n\nIt is possible to use a single S3 bucket for storing kops state for clusters\nlocated in different accounts, by using [cross-account bucket policies](http://docs.aws.amazon.com/AmazonS3/latest/dev/example-walkthroughs-managing-access-example2.html#access-policies-walkthrough-cross-account-permissions-acctA-tasks).\n\nKops will be able to use buckets configured with cross-account policies by default.\n\nIn this case you may want to override the object ACLs which kops places on the\nstate files, as default AWS ACLs will make it possible for an account that has\ndelegated access to write files that the bucket owner can not read.\n\nTo do this you should set the environment variable `KOPS_STATE_S3_ACL` to the\npreferred object ACL, for example `bucket-owner-full-control`.\n\nFor available canned ACLs please consult [Amazon's S3\ndocumentation](http://docs.aws.amazon.com/AmazonS3/latest/dev/acl-overview.html#canned-acl).\n\n# Creating your first cluster\n\n## Prepare local environment\n\nWe're ready to start creating our first cluster!  Let's first set up a few\nenvironment variables to make this process easier.\n\n```bash\nexport NAME=myfirstcluster.example.com\nexport KOPS_STATE_STORE=s3://prefix-example-com-state-store\n```\n\nFor a gossip-based cluster, make sure the name ends with `k8s.local`. For example:\n\n```bash\nexport NAME=myfirstcluster.k8s.local\nexport KOPS_STATE_STORE=s3://prefix-example-com-state-store\n```\n\nNote: You don’t have to use environmental variables here. You can always define\nthe values using the –name and –state flags later.\n\n## Create cluster configuration\n\nWe will need to note which availability zones are available to us. In this\nexample we will be deploying our cluster to the us-west-2 region.\n\n```bash\naws ec2 describe-availability-zones --region us-west-2\n```\n\nBelow is a create cluster command.  We'll use the most basic example possible,\nwith more verbose examples in [high availability](high_availability.md#advanced-example).\nThe below command will generate a cluster configuration, but not start building\nit. Make sure that you have generated SSH key pair before creating the cluster.\n\n```bash\nkops create cluster \\\n    --zones us-west-2a \\\n    ${NAME}\n```\n\nAll instances created by `kops` will be built within ASG (Auto Scaling Groups),\nwhich means each instance will be automatically monitored and rebuilt by AWS if\nit suffers any failure.\n\n## Customize Cluster Configuration\n\nNow we have a cluster configuration, we can look at every aspect that defines\nour cluster by editing the description.\n\n```bash\nkops edit cluster ${NAME}\n```\n\nThis opens your editor (as defined by $EDITOR) and allows you to edit the\nconfiguration.  The configuration is loaded from the S3 bucket we created\nearlier, and automatically updated when we save and exit the editor.\n\nWe'll leave everything set to the defaults for now, but the rest of the `kops`\ndocumentation covers additional settings and configuration you can enable.\n\n## Build the Cluster\n\nNow we take the final step of actually building the cluster.  This'll take a\nwhile.  Once it finishes you'll have to wait longer while the booted instances\nfinish downloading Kubernetes components and reach a \"ready\" state.\n\n```bash\nkops update cluster ${NAME} --yes\n```\n\n## Use the Cluster\n\nRemember when you installed `kubectl` earlier? The configuration for your\ncluster was automatically generated and written to `~/.kube/config` for you!\n\nA simple Kubernetes API call can be used to check if the API is online and\nlistening. Let's use `kubectl` to check the nodes.\n\n```bash\nkubectl get nodes\n```\n\nYou will see a list of nodes that should match the `--zones` flag defined\nearlier. This is a great sign that your Kubernetes cluster is online and\nworking.\n\nAlso `kops` ships with a handy validation tool that can be ran to ensure your\ncluster is working as expected.\n\n```bash\nkops validate cluster\n```\n\nYou can look at all the system components with the following command.\n\n```\nkubectl -n kube-system get po\n```\n\n## Delete the Cluster\n\nRunning a Kubernetes cluster within AWS obviously costs money, and so you may\nwant to delete your cluster if you are finished running experiments.\n\nYou can preview all of the AWS resources that will be destroyed when the cluster\nis deleted by issuing the following command.\n\n```\nkops delete cluster --name ${NAME}\n```\n\nWhen you are sure you want to delete your cluster, issue the delete command\nwith the `--yes` flag. Note that this command is very destructive, and will\ndelete your cluster and everything contained within it!\n\n```\nkops delete cluster --name ${NAME} --yes\n```\n\n# What's next?\n\nWe've barely scratched the surface of the capabilities of `kops` in this guide,\nand we recommend researching [other interesting\nmodes](commands.md#other-interesting-modes) to learn more about generating\nTerraform configurations, or running your cluster in an HA (Highly Available)\nmode.\n\nThe [cluster spec docs](cluster_spec.md) can help to configure these \"other\ninteresting modes\". Also be sure to check out how to run a [private network\ntopology](topology.md) in AWS.\n\n## Feedback\n\nThere's an incredible team behind Kops and we encourage you to reach out to the\ncommunity on the Kubernetes\nSlack(http://slack.k8s.io/).  Bring your\nquestions, comments, and requests and meet the people behind the project!\n\n## Legal\n\n*AWS Trademark used with limited permission under the [AWS Trademark\nGuidelines](https://aws.amazon.com/trademark-guidelines/)*\n\n*Kubernetes Logo used with permission under the [Kubernetes Branding\nGuidelines](https://github.com/kubernetes/kubernetes/blob/master/logo/usage_guidelines.md)*","slug":"kops","published":1,"updated":"2017-12-17T07:17:24.900Z","_id":"cjbafkkgp000037oh12sl7tsc","comments":1,"layout":"post","photos":[],"link":"","content":"<p align=\"center\"><br>  <img src=\"img/k8s-aws.png\"> <br></p>\n\n<h1 id=\"Getting-Started\"><a href=\"#Getting-Started\" class=\"headerlink\" title=\"Getting Started\"></a>Getting Started</h1><h2 id=\"Install-kops\"><a href=\"#Install-kops\" class=\"headerlink\" title=\"Install kops\"></a>Install kops</h2><p>Before we can bring up the cluster we need to <a href=\"install.md\">install the CLI tool</a> <code>kops</code>.</p>\n<h2 id=\"Install-kubectl\"><a href=\"#Install-kubectl\" class=\"headerlink\" title=\"Install kubectl\"></a>Install kubectl</h2><p>In order to control Kubernetes clusters we need to <a href=\"install.md\">install the CLI tool</a> <code>kubectl</code>.</p>\n<h4 id=\"Other-Platforms\"><a href=\"#Other-Platforms\" class=\"headerlink\" title=\"Other Platforms\"></a>Other Platforms</h4><ul>\n<li><p><a href=\"https://github.com/kubernetes/kubernetes/releases/latest\" target=\"_blank\" rel=\"noopener\">Kubernetes Latest Release</a></p>\n</li>\n<li><p><a href=\"http://kubernetes.io/docs/user-guide/prereqs/\" target=\"_blank\" rel=\"noopener\">Installation Guide</a></p>\n</li>\n</ul>\n<h2 id=\"Setup-your-environment\"><a href=\"#Setup-your-environment\" class=\"headerlink\" title=\"Setup your environment\"></a>Setup your environment</h2><h3 id=\"AWS\"><a href=\"#AWS\" class=\"headerlink\" title=\"AWS\"></a>AWS</h3><p>In order to correctly prepare your AWS account for <code>kops</code>, we require you to<br>install the AWS CLI tools, and have API credentials for an account that has<br>the permissions to create a new IAM account for <code>kops</code> later in the guide.</p>\n<p>Once you’ve <a href=\"install.md\">installed the AWS CLI tools</a> and have correctly setup<br>your system to use the official AWS methods of registering security credentials<br>as <a href=\"https://docs.aws.amazon.com/sdk-for-go/v1/developer-guide/configuring-sdk.html#specifying-credentials\" target=\"_blank\" rel=\"noopener\">defined here</a> we’ll be ready to run <code>kops</code>, as it uses the Go AWS SDK.</p>\n<h4 id=\"Setup-IAM-user\"><a href=\"#Setup-IAM-user\" class=\"headerlink\" title=\"Setup IAM user\"></a>Setup IAM user</h4><p>In order to build clusters within AWS we’ll create a dedicated IAM user for<br><code>kops</code>.  This user requires API credentials in order to use <code>kops</code>.  Create<br>the user, and credentials, using the <a href=\"http://docs.aws.amazon.com/IAM/latest/UserGuide/id_users_create.html#id_users_create_console\" target=\"_blank\" rel=\"noopener\">AWS console</a>.</p>\n<p>The <code>kops</code> user will require the following IAM permissions to function properly:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">AmazonEC2FullAccess</span><br><span class=\"line\">AmazonRoute53FullAccess</span><br><span class=\"line\">AmazonS3FullAccess</span><br><span class=\"line\">IAMFullAccess</span><br><span class=\"line\">AmazonVPCFullAccess</span><br></pre></td></tr></table></figure>\n<p>You can create the kops IAM user from the command line using the following:</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">aws iam create-group --group-name kops</span><br><span class=\"line\"></span><br><span class=\"line\">aws iam attach-group-policy --policy-arn arn:aws:iam::aws:policy/AmazonEC2FullAccess --group-name kops</span><br><span class=\"line\">aws iam attach-group-policy --policy-arn arn:aws:iam::aws:policy/AmazonRoute53FullAccess --group-name kops</span><br><span class=\"line\">aws iam attach-group-policy --policy-arn arn:aws:iam::aws:policy/AmazonS3FullAccess --group-name kops</span><br><span class=\"line\">aws iam attach-group-policy --policy-arn arn:aws:iam::aws:policy/IAMFullAccess --group-name kops</span><br><span class=\"line\">aws iam attach-group-policy --policy-arn arn:aws:iam::aws:policy/AmazonVPCFullAccess --group-name kops</span><br><span class=\"line\"></span><br><span class=\"line\">aws iam create-user --user-name kops</span><br><span class=\"line\"></span><br><span class=\"line\">aws iam add-user-to-group --user-name kops --group-name kops</span><br><span class=\"line\"></span><br><span class=\"line\">aws iam create-access-key --user-name kops</span><br></pre></td></tr></table></figure>\n<p>You should record the SecretAccessKey and AccessKeyID in the returned JSON<br>output, and then use them below:</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># configure the aws client to use your new IAM user</span></span><br><span class=\"line\">aws configure           <span class=\"comment\"># Use your new access and secret key here</span></span><br><span class=\"line\">aws iam list-users      <span class=\"comment\"># you should see a list of all your IAM users here</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Because \"aws configure\" doesn't export these vars for kops to use, we export them now</span></span><br><span class=\"line\"><span class=\"built_in\">export</span> AWS_ACCESS_KEY_ID=$(aws configure get aws_access_key_id)</span><br><span class=\"line\"><span class=\"built_in\">export</span> AWS_SECRET_ACCESS_KEY=$(aws configure get aws_secret_access_key)</span><br></pre></td></tr></table></figure>\n<h2 id=\"Configure-DNS\"><a href=\"#Configure-DNS\" class=\"headerlink\" title=\"Configure DNS\"></a>Configure DNS</h2><p>Note: If you are using Kops 1.6.2 or later, then DNS configuration is<br>optional. Instead, a gossip-based cluster can be easily created. The<br>only requirement to trigger this is to have the cluster name end with<br><code>.k8s.local</code>. If a gossip-based cluster is created then you can skip<br>this section.</p>\n<p>In order to build a Kubernetes cluster with <code>kops</code>, we need to prepare<br>somewhere to build the required DNS records.  There are three scenarios<br>below and you should choose the one that most closely matches your AWS<br>situation.</p>\n<h3 id=\"Scenario-1a-A-Domain-purchased-hosted-via-AWS\"><a href=\"#Scenario-1a-A-Domain-purchased-hosted-via-AWS\" class=\"headerlink\" title=\"Scenario 1a: A Domain purchased/hosted via AWS\"></a>Scenario 1a: A Domain purchased/hosted via AWS</h3><p>If you bought your domain with AWS, then you should already have a hosted zone<br>in Route53.  If you plan to use this domain then no more work is needed.</p>\n<p>In this example you own <code>example.com</code> and your records for Kubernetes would<br>look like <code>etcd-us-east-1c.internal.clustername.example.com</code></p>\n<h3 id=\"Scenario-1b-A-subdomain-under-a-domain-purchased-hosted-via-AWS\"><a href=\"#Scenario-1b-A-subdomain-under-a-domain-purchased-hosted-via-AWS\" class=\"headerlink\" title=\"Scenario 1b: A subdomain under a domain purchased/hosted via AWS\"></a>Scenario 1b: A subdomain under a domain purchased/hosted via AWS</h3><p>In this scenario you want to contain all kubernetes records under a subdomain<br>of a domain you host in Route53.  This requires creating a second hosted zone<br>in route53, and then setting up route delegation to the new zone.</p>\n<p>In this example you own <code>example.com</code> and your records for Kubernetes would<br>look like <code>etcd-us-east-1c.internal.clustername.subdomain.example.com</code></p>\n<p>This is copying the NS servers of your <strong>SUBDOMAIN</strong> up to the <strong>PARENT</strong><br>domain in Route53.  To do this you should:</p>\n<ul>\n<li>Create the subdomain, and note your <strong>SUBDOMAIN</strong> name servers (If you have<br>already done this you can also <a href=\"ns.md\">get the values</a>)</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Note: This example assumes you have jq installed locally.</span></span><br><span class=\"line\">ID=$(uuidgen) &amp;&amp; aws route53 create-hosted-zone --name subdomain.example.com --<span class=\"built_in\">caller</span>-reference <span class=\"variable\">$ID</span> | \\</span><br><span class=\"line\">    jq .DelegationSet.NameServers</span><br></pre></td></tr></table></figure>\n<ul>\n<li>Note your <strong>PARENT</strong> hosted zone id</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Note: This example assumes you have jq installed locally.</span></span><br><span class=\"line\">aws route53 list-hosted-zones | jq <span class=\"string\">'.HostedZones[] | select(.Name==\"example.com.\") | .Id'</span></span><br></pre></td></tr></table></figure>\n<ul>\n<li>Create a new JSON file with your values (<code>subdomain.json</code>)</li>\n</ul>\n<p>Note: The NS values here are for the <strong>SUBDOMAIN</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;</span><br><span class=\"line\">  &quot;Comment&quot;: &quot;Create a subdomain NS record in the parent domain&quot;,</span><br><span class=\"line\">  &quot;Changes&quot;: [</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">      &quot;Action&quot;: &quot;CREATE&quot;,</span><br><span class=\"line\">      &quot;ResourceRecordSet&quot;: &#123;</span><br><span class=\"line\">        &quot;Name&quot;: &quot;subdomain.example.com&quot;,</span><br><span class=\"line\">        &quot;Type&quot;: &quot;NS&quot;,</span><br><span class=\"line\">        &quot;TTL&quot;: 300,</span><br><span class=\"line\">        &quot;ResourceRecords&quot;: [</span><br><span class=\"line\">          &#123;</span><br><span class=\"line\">            &quot;Value&quot;: &quot;ns-1.awsdns-1.co.uk&quot;</span><br><span class=\"line\">          &#125;,</span><br><span class=\"line\">          &#123;</span><br><span class=\"line\">            &quot;Value&quot;: &quot;ns-2.awsdns-2.org&quot;</span><br><span class=\"line\">          &#125;,</span><br><span class=\"line\">          &#123;</span><br><span class=\"line\">            &quot;Value&quot;: &quot;ns-3.awsdns-3.com&quot;</span><br><span class=\"line\">          &#125;,</span><br><span class=\"line\">          &#123;</span><br><span class=\"line\">            &quot;Value&quot;: &quot;ns-4.awsdns-4.net&quot;</span><br><span class=\"line\">          &#125;</span><br><span class=\"line\">        ]</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  ]</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<ul>\n<li>Apply the <strong>SUBDOMAIN</strong> NS records to the <strong>PARENT</strong> hosted zone.</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">aws route53 change-resource-record-sets \\</span><br><span class=\"line\"> --hosted-zone-id &lt;parent-zone-id&gt; \\</span><br><span class=\"line\"> --change-batch file://subdomain.json</span><br></pre></td></tr></table></figure>\n<p>Now traffic to <code>*.subdomain.example.com</code> will be routed to the correct subdomain hosted zone in Route53.</p>\n<h3 id=\"Scenario-2-Setting-up-Route53-for-a-domain-purchased-with-another-registrar\"><a href=\"#Scenario-2-Setting-up-Route53-for-a-domain-purchased-with-another-registrar\" class=\"headerlink\" title=\"Scenario 2: Setting up Route53 for a domain purchased with another registrar\"></a>Scenario 2: Setting up Route53 for a domain purchased with another registrar</h3><p>If you bought your domain elsewhere, and would like to dedicate the entire domain to AWS you should follow the guide <a href=\"http://docs.aws.amazon.com/Route53/latest/DeveloperGuide/domain-transfer-to-route-53.html\" target=\"_blank\" rel=\"noopener\">here</a></p>\n<h3 id=\"Scenario-3-Subdomain-for-clusters-in-route53-leaving-the-domain-at-another-registrar\"><a href=\"#Scenario-3-Subdomain-for-clusters-in-route53-leaving-the-domain-at-another-registrar\" class=\"headerlink\" title=\"Scenario 3: Subdomain for clusters in route53, leaving the domain at another registrar\"></a>Scenario 3: Subdomain for clusters in route53, leaving the domain at another registrar</h3><p>If you bought your domain elsewhere, but <strong>only want to use a subdomain in AWS<br>Route53</strong> you must modify your registrar’s NS (NameServer) records.  We’ll create<br>a hosted zone in Route53, and then migrate the subdomain’s NS records to your<br>other registrar.</p>\n<p>You might need to grab <a href=\"https://github.com/stedolan/jq/wiki/Installation\" target=\"_blank\" rel=\"noopener\">jq</a><br>for some of these instructions.</p>\n<ul>\n<li>Create the subdomain, and note your name servers (If you have already done<br>this you can also <a href=\"ns.md\">get the values</a>)</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ID=$(uuidgen) &amp;&amp; aws route53 create-hosted-zone --name subdomain.example.com --<span class=\"built_in\">caller</span>-reference <span class=\"variable\">$ID</span> | jq .DelegationSet.NameServers</span><br></pre></td></tr></table></figure>\n<ul>\n<li><p>You will now go to your registrar’s page and log in. You will need to create a<br>new <strong>SUBDOMAIN</strong>, and use the 4 NS records received from the above command for the new<br><strong>SUBDOMAIN</strong>. This <strong>MUST</strong> be done in order to use your cluster. Do <strong>NOT</strong><br>change your top level NS record, or you might take your site offline.</p>\n</li>\n<li><p>Information on adding NS records with<br><a href=\"https://www.godaddy.com/help/set-custom-nameservers-for-domains-registered-with-godaddy-12317\" target=\"_blank\" rel=\"noopener\">Godaddy.com</a></p>\n</li>\n<li>Information on adding NS records with <a href=\"https://cloud.google.com/dns/update-name-servers\" target=\"_blank\" rel=\"noopener\">Google Cloud<br>Platform</a></li>\n</ul>\n<h4 id=\"Using-Public-Private-DNS-Kops-1-5\"><a href=\"#Using-Public-Private-DNS-Kops-1-5\" class=\"headerlink\" title=\"Using Public/Private DNS (Kops 1.5+)\"></a>Using Public/Private DNS (Kops 1.5+)</h4><p>By default the assumption is that NS records are publically available.  If you<br>require private DNS records you should modify the commands we run later in this<br>guide to include:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kops create cluster --dns private $NAME</span><br></pre></td></tr></table></figure>\n<p>If you have a mix of public and private zones, you will also need to include the <code>--dns-zone</code> argument with the hosted zone id you wish to deploy in:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kops create cluster --dns private --dns-zone ZABCDEFG $NAME</span><br></pre></td></tr></table></figure>\n<h2 id=\"Testing-your-DNS-setup\"><a href=\"#Testing-your-DNS-setup\" class=\"headerlink\" title=\"Testing your DNS setup\"></a>Testing your DNS setup</h2><p>This section is not be required if a gossip-based cluster is created.</p>\n<p>You should now able to dig your domain (or subdomain) and see the AWS Name<br>Servers on the other end.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">dig ns subdomain.example.com</span><br></pre></td></tr></table></figure>\n<p>Should return something similar to:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">;; ANSWER SECTION:</span><br><span class=\"line\">subdomain.example.com.        172800  IN  NS  ns-1.awsdns-1.net.</span><br><span class=\"line\">subdomain.example.com.        172800  IN  NS  ns-2.awsdns-2.org.</span><br><span class=\"line\">subdomain.example.com.        172800  IN  NS  ns-3.awsdns-3.com.</span><br><span class=\"line\">subdomain.example.com.        172800  IN  NS  ns-4.awsdns-4.co.uk.</span><br></pre></td></tr></table></figure>\n<p>This is a critical component of setting up clusters. If you are experiencing<br>problems with the Kubernetes API not coming up, chances are something is wrong<br>with the cluster’s DNS.</p>\n<p><strong>Please DO NOT MOVE ON until you have validated your NS records! This is not be required if a gossip-based cluster is created.</strong></p>\n<h2 id=\"Cluster-State-storage\"><a href=\"#Cluster-State-storage\" class=\"headerlink\" title=\"Cluster State storage\"></a>Cluster State storage</h2><p>In order to store the state of your cluster, and the representation of your<br>cluster, we need to create a dedicated S3 bucket for <code>kops</code> to use.  This<br>bucket will become the source of truth for our cluster configuration.  In<br>this guide we’ll call this bucket <code>example-com-state-store</code>, but you should<br>add a custom prefix as bucket names need to be unique.</p>\n<p>We recommend keeping the creation of this bucket confined to us-east-1,<br>otherwise more work will be required.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">aws s3api create-bucket \\</span><br><span class=\"line\">    --bucket prefix-example-com-state-store \\</span><br><span class=\"line\">    --region us-east-1</span><br></pre></td></tr></table></figure>\n<p>Note: S3 requires <code>--create-bucket-configuration LocationConstraint=&lt;region&gt;</code> for regions other than <code>us-east-1</code>.</p>\n<p>Note: We <strong>STRONGLY</strong> recommend versioning your S3 bucket in case you ever need<br>to revert or recover a previous state store.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">aws s3api put-bucket-versioning --bucket prefix-example-com-state-store  --versioning-configuration Status=Enabled</span><br></pre></td></tr></table></figure>\n<h3 id=\"Sharing-an-S3-bucket-across-multiple-accounts\"><a href=\"#Sharing-an-S3-bucket-across-multiple-accounts\" class=\"headerlink\" title=\"Sharing an S3 bucket across multiple accounts\"></a>Sharing an S3 bucket across multiple accounts</h3><p>It is possible to use a single S3 bucket for storing kops state for clusters<br>located in different accounts, by using <a href=\"http://docs.aws.amazon.com/AmazonS3/latest/dev/example-walkthroughs-managing-access-example2.html#access-policies-walkthrough-cross-account-permissions-acctA-tasks\" target=\"_blank\" rel=\"noopener\">cross-account bucket policies</a>.</p>\n<p>Kops will be able to use buckets configured with cross-account policies by default.</p>\n<p>In this case you may want to override the object ACLs which kops places on the<br>state files, as default AWS ACLs will make it possible for an account that has<br>delegated access to write files that the bucket owner can not read.</p>\n<p>To do this you should set the environment variable <code>KOPS_STATE_S3_ACL</code> to the<br>preferred object ACL, for example <code>bucket-owner-full-control</code>.</p>\n<p>For available canned ACLs please consult <a href=\"http://docs.aws.amazon.com/AmazonS3/latest/dev/acl-overview.html#canned-acl\" target=\"_blank\" rel=\"noopener\">Amazon’s S3<br>documentation</a>.</p>\n<h1 id=\"Creating-your-first-cluster\"><a href=\"#Creating-your-first-cluster\" class=\"headerlink\" title=\"Creating your first cluster\"></a>Creating your first cluster</h1><h2 id=\"Prepare-local-environment\"><a href=\"#Prepare-local-environment\" class=\"headerlink\" title=\"Prepare local environment\"></a>Prepare local environment</h2><p>We’re ready to start creating our first cluster!  Let’s first set up a few<br>environment variables to make this process easier.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">export</span> NAME=myfirstcluster.example.com</span><br><span class=\"line\"><span class=\"built_in\">export</span> KOPS_STATE_STORE=s3://prefix-example-com-state-store</span><br></pre></td></tr></table></figure>\n<p>For a gossip-based cluster, make sure the name ends with <code>k8s.local</code>. For example:</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">export</span> NAME=myfirstcluster.k8s.local</span><br><span class=\"line\"><span class=\"built_in\">export</span> KOPS_STATE_STORE=s3://prefix-example-com-state-store</span><br></pre></td></tr></table></figure>\n<p>Note: You don’t have to use environmental variables here. You can always define<br>the values using the –name and –state flags later.</p>\n<h2 id=\"Create-cluster-configuration\"><a href=\"#Create-cluster-configuration\" class=\"headerlink\" title=\"Create cluster configuration\"></a>Create cluster configuration</h2><p>We will need to note which availability zones are available to us. In this<br>example we will be deploying our cluster to the us-west-2 region.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">aws ec2 describe-availability-zones --region us-west-2</span><br></pre></td></tr></table></figure>\n<p>Below is a create cluster command.  We’ll use the most basic example possible,<br>with more verbose examples in <a href=\"high_availability.md#advanced-example\">high availability</a>.<br>The below command will generate a cluster configuration, but not start building<br>it. Make sure that you have generated SSH key pair before creating the cluster.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kops create cluster \\</span><br><span class=\"line\">    --zones us-west-2a \\</span><br><span class=\"line\">    <span class=\"variable\">$&#123;NAME&#125;</span></span><br></pre></td></tr></table></figure>\n<p>All instances created by <code>kops</code> will be built within ASG (Auto Scaling Groups),<br>which means each instance will be automatically monitored and rebuilt by AWS if<br>it suffers any failure.</p>\n<h2 id=\"Customize-Cluster-Configuration\"><a href=\"#Customize-Cluster-Configuration\" class=\"headerlink\" title=\"Customize Cluster Configuration\"></a>Customize Cluster Configuration</h2><p>Now we have a cluster configuration, we can look at every aspect that defines<br>our cluster by editing the description.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kops edit cluster <span class=\"variable\">$&#123;NAME&#125;</span></span><br></pre></td></tr></table></figure>\n<p>This opens your editor (as defined by $EDITOR) and allows you to edit the<br>configuration.  The configuration is loaded from the S3 bucket we created<br>earlier, and automatically updated when we save and exit the editor.</p>\n<p>We’ll leave everything set to the defaults for now, but the rest of the <code>kops</code><br>documentation covers additional settings and configuration you can enable.</p>\n<h2 id=\"Build-the-Cluster\"><a href=\"#Build-the-Cluster\" class=\"headerlink\" title=\"Build the Cluster\"></a>Build the Cluster</h2><p>Now we take the final step of actually building the cluster.  This’ll take a<br>while.  Once it finishes you’ll have to wait longer while the booted instances<br>finish downloading Kubernetes components and reach a “ready” state.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kops update cluster <span class=\"variable\">$&#123;NAME&#125;</span> --yes</span><br></pre></td></tr></table></figure>\n<h2 id=\"Use-the-Cluster\"><a href=\"#Use-the-Cluster\" class=\"headerlink\" title=\"Use the Cluster\"></a>Use the Cluster</h2><p>Remember when you installed <code>kubectl</code> earlier? The configuration for your<br>cluster was automatically generated and written to <code>~/.kube/config</code> for you!</p>\n<p>A simple Kubernetes API call can be used to check if the API is online and<br>listening. Let’s use <code>kubectl</code> to check the nodes.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kubectl get nodes</span><br></pre></td></tr></table></figure>\n<p>You will see a list of nodes that should match the <code>--zones</code> flag defined<br>earlier. This is a great sign that your Kubernetes cluster is online and<br>working.</p>\n<p>Also <code>kops</code> ships with a handy validation tool that can be ran to ensure your<br>cluster is working as expected.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kops validate cluster</span><br></pre></td></tr></table></figure>\n<p>You can look at all the system components with the following command.</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kubectl -n kube-system get po</span><br></pre></td></tr></table></figure>\n<h2 id=\"Delete-the-Cluster\"><a href=\"#Delete-the-Cluster\" class=\"headerlink\" title=\"Delete the Cluster\"></a>Delete the Cluster</h2><p>Running a Kubernetes cluster within AWS obviously costs money, and so you may<br>want to delete your cluster if you are finished running experiments.</p>\n<p>You can preview all of the AWS resources that will be destroyed when the cluster<br>is deleted by issuing the following command.</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kops delete cluster --name $&#123;NAME&#125;</span><br></pre></td></tr></table></figure>\n<p>When you are sure you want to delete your cluster, issue the delete command<br>with the <code>--yes</code> flag. Note that this command is very destructive, and will<br>delete your cluster and everything contained within it!</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kops delete cluster --name $&#123;NAME&#125; --yes</span><br></pre></td></tr></table></figure>\n<h1 id=\"What’s-next\"><a href=\"#What’s-next\" class=\"headerlink\" title=\"What’s next?\"></a>What’s next?</h1><p>We’ve barely scratched the surface of the capabilities of <code>kops</code> in this guide,<br>and we recommend researching <a href=\"commands.md#other-interesting-modes\">other interesting<br>modes</a> to learn more about generating<br>Terraform configurations, or running your cluster in an HA (Highly Available)<br>mode.</p>\n<p>The <a href=\"cluster_spec.md\">cluster spec docs</a> can help to configure these “other<br>interesting modes”. Also be sure to check out how to run a <a href=\"topology.md\">private network<br>topology</a> in AWS.</p>\n<h2 id=\"Feedback\"><a href=\"#Feedback\" class=\"headerlink\" title=\"Feedback\"></a>Feedback</h2><p>There’s an incredible team behind Kops and we encourage you to reach out to the<br>community on the Kubernetes<br>Slack(<a href=\"http://slack.k8s.io/\" target=\"_blank\" rel=\"noopener\">http://slack.k8s.io/</a>).  Bring your<br>questions, comments, and requests and meet the people behind the project!</p>\n<h2 id=\"Legal\"><a href=\"#Legal\" class=\"headerlink\" title=\"Legal\"></a>Legal</h2><p><em>AWS Trademark used with limited permission under the <a href=\"https://aws.amazon.com/trademark-guidelines/\" target=\"_blank\" rel=\"noopener\">AWS Trademark<br>Guidelines</a></em></p>\n<p><em>Kubernetes Logo used with permission under the <a href=\"https://github.com/kubernetes/kubernetes/blob/master/logo/usage_guidelines.md\" target=\"_blank\" rel=\"noopener\">Kubernetes Branding<br>Guidelines</a></em></p>\n","site":{"data":{}},"excerpt":"","more":"<p align=\"center\"><br>  <img src=\"img/k8s-aws.png\"> <br></p>\n\n<h1 id=\"Getting-Started\"><a href=\"#Getting-Started\" class=\"headerlink\" title=\"Getting Started\"></a>Getting Started</h1><h2 id=\"Install-kops\"><a href=\"#Install-kops\" class=\"headerlink\" title=\"Install kops\"></a>Install kops</h2><p>Before we can bring up the cluster we need to <a href=\"install.md\">install the CLI tool</a> <code>kops</code>.</p>\n<h2 id=\"Install-kubectl\"><a href=\"#Install-kubectl\" class=\"headerlink\" title=\"Install kubectl\"></a>Install kubectl</h2><p>In order to control Kubernetes clusters we need to <a href=\"install.md\">install the CLI tool</a> <code>kubectl</code>.</p>\n<h4 id=\"Other-Platforms\"><a href=\"#Other-Platforms\" class=\"headerlink\" title=\"Other Platforms\"></a>Other Platforms</h4><ul>\n<li><p><a href=\"https://github.com/kubernetes/kubernetes/releases/latest\" target=\"_blank\" rel=\"noopener\">Kubernetes Latest Release</a></p>\n</li>\n<li><p><a href=\"http://kubernetes.io/docs/user-guide/prereqs/\" target=\"_blank\" rel=\"noopener\">Installation Guide</a></p>\n</li>\n</ul>\n<h2 id=\"Setup-your-environment\"><a href=\"#Setup-your-environment\" class=\"headerlink\" title=\"Setup your environment\"></a>Setup your environment</h2><h3 id=\"AWS\"><a href=\"#AWS\" class=\"headerlink\" title=\"AWS\"></a>AWS</h3><p>In order to correctly prepare your AWS account for <code>kops</code>, we require you to<br>install the AWS CLI tools, and have API credentials for an account that has<br>the permissions to create a new IAM account for <code>kops</code> later in the guide.</p>\n<p>Once you’ve <a href=\"install.md\">installed the AWS CLI tools</a> and have correctly setup<br>your system to use the official AWS methods of registering security credentials<br>as <a href=\"https://docs.aws.amazon.com/sdk-for-go/v1/developer-guide/configuring-sdk.html#specifying-credentials\" target=\"_blank\" rel=\"noopener\">defined here</a> we’ll be ready to run <code>kops</code>, as it uses the Go AWS SDK.</p>\n<h4 id=\"Setup-IAM-user\"><a href=\"#Setup-IAM-user\" class=\"headerlink\" title=\"Setup IAM user\"></a>Setup IAM user</h4><p>In order to build clusters within AWS we’ll create a dedicated IAM user for<br><code>kops</code>.  This user requires API credentials in order to use <code>kops</code>.  Create<br>the user, and credentials, using the <a href=\"http://docs.aws.amazon.com/IAM/latest/UserGuide/id_users_create.html#id_users_create_console\" target=\"_blank\" rel=\"noopener\">AWS console</a>.</p>\n<p>The <code>kops</code> user will require the following IAM permissions to function properly:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">AmazonEC2FullAccess</span><br><span class=\"line\">AmazonRoute53FullAccess</span><br><span class=\"line\">AmazonS3FullAccess</span><br><span class=\"line\">IAMFullAccess</span><br><span class=\"line\">AmazonVPCFullAccess</span><br></pre></td></tr></table></figure>\n<p>You can create the kops IAM user from the command line using the following:</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">aws iam create-group --group-name kops</span><br><span class=\"line\"></span><br><span class=\"line\">aws iam attach-group-policy --policy-arn arn:aws:iam::aws:policy/AmazonEC2FullAccess --group-name kops</span><br><span class=\"line\">aws iam attach-group-policy --policy-arn arn:aws:iam::aws:policy/AmazonRoute53FullAccess --group-name kops</span><br><span class=\"line\">aws iam attach-group-policy --policy-arn arn:aws:iam::aws:policy/AmazonS3FullAccess --group-name kops</span><br><span class=\"line\">aws iam attach-group-policy --policy-arn arn:aws:iam::aws:policy/IAMFullAccess --group-name kops</span><br><span class=\"line\">aws iam attach-group-policy --policy-arn arn:aws:iam::aws:policy/AmazonVPCFullAccess --group-name kops</span><br><span class=\"line\"></span><br><span class=\"line\">aws iam create-user --user-name kops</span><br><span class=\"line\"></span><br><span class=\"line\">aws iam add-user-to-group --user-name kops --group-name kops</span><br><span class=\"line\"></span><br><span class=\"line\">aws iam create-access-key --user-name kops</span><br></pre></td></tr></table></figure>\n<p>You should record the SecretAccessKey and AccessKeyID in the returned JSON<br>output, and then use them below:</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># configure the aws client to use your new IAM user</span></span><br><span class=\"line\">aws configure           <span class=\"comment\"># Use your new access and secret key here</span></span><br><span class=\"line\">aws iam list-users      <span class=\"comment\"># you should see a list of all your IAM users here</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Because \"aws configure\" doesn't export these vars for kops to use, we export them now</span></span><br><span class=\"line\"><span class=\"built_in\">export</span> AWS_ACCESS_KEY_ID=$(aws configure get aws_access_key_id)</span><br><span class=\"line\"><span class=\"built_in\">export</span> AWS_SECRET_ACCESS_KEY=$(aws configure get aws_secret_access_key)</span><br></pre></td></tr></table></figure>\n<h2 id=\"Configure-DNS\"><a href=\"#Configure-DNS\" class=\"headerlink\" title=\"Configure DNS\"></a>Configure DNS</h2><p>Note: If you are using Kops 1.6.2 or later, then DNS configuration is<br>optional. Instead, a gossip-based cluster can be easily created. The<br>only requirement to trigger this is to have the cluster name end with<br><code>.k8s.local</code>. If a gossip-based cluster is created then you can skip<br>this section.</p>\n<p>In order to build a Kubernetes cluster with <code>kops</code>, we need to prepare<br>somewhere to build the required DNS records.  There are three scenarios<br>below and you should choose the one that most closely matches your AWS<br>situation.</p>\n<h3 id=\"Scenario-1a-A-Domain-purchased-hosted-via-AWS\"><a href=\"#Scenario-1a-A-Domain-purchased-hosted-via-AWS\" class=\"headerlink\" title=\"Scenario 1a: A Domain purchased/hosted via AWS\"></a>Scenario 1a: A Domain purchased/hosted via AWS</h3><p>If you bought your domain with AWS, then you should already have a hosted zone<br>in Route53.  If you plan to use this domain then no more work is needed.</p>\n<p>In this example you own <code>example.com</code> and your records for Kubernetes would<br>look like <code>etcd-us-east-1c.internal.clustername.example.com</code></p>\n<h3 id=\"Scenario-1b-A-subdomain-under-a-domain-purchased-hosted-via-AWS\"><a href=\"#Scenario-1b-A-subdomain-under-a-domain-purchased-hosted-via-AWS\" class=\"headerlink\" title=\"Scenario 1b: A subdomain under a domain purchased/hosted via AWS\"></a>Scenario 1b: A subdomain under a domain purchased/hosted via AWS</h3><p>In this scenario you want to contain all kubernetes records under a subdomain<br>of a domain you host in Route53.  This requires creating a second hosted zone<br>in route53, and then setting up route delegation to the new zone.</p>\n<p>In this example you own <code>example.com</code> and your records for Kubernetes would<br>look like <code>etcd-us-east-1c.internal.clustername.subdomain.example.com</code></p>\n<p>This is copying the NS servers of your <strong>SUBDOMAIN</strong> up to the <strong>PARENT</strong><br>domain in Route53.  To do this you should:</p>\n<ul>\n<li>Create the subdomain, and note your <strong>SUBDOMAIN</strong> name servers (If you have<br>already done this you can also <a href=\"ns.md\">get the values</a>)</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Note: This example assumes you have jq installed locally.</span></span><br><span class=\"line\">ID=$(uuidgen) &amp;&amp; aws route53 create-hosted-zone --name subdomain.example.com --<span class=\"built_in\">caller</span>-reference <span class=\"variable\">$ID</span> | \\</span><br><span class=\"line\">    jq .DelegationSet.NameServers</span><br></pre></td></tr></table></figure>\n<ul>\n<li>Note your <strong>PARENT</strong> hosted zone id</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Note: This example assumes you have jq installed locally.</span></span><br><span class=\"line\">aws route53 list-hosted-zones | jq <span class=\"string\">'.HostedZones[] | select(.Name==\"example.com.\") | .Id'</span></span><br></pre></td></tr></table></figure>\n<ul>\n<li>Create a new JSON file with your values (<code>subdomain.json</code>)</li>\n</ul>\n<p>Note: The NS values here are for the <strong>SUBDOMAIN</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;</span><br><span class=\"line\">  &quot;Comment&quot;: &quot;Create a subdomain NS record in the parent domain&quot;,</span><br><span class=\"line\">  &quot;Changes&quot;: [</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">      &quot;Action&quot;: &quot;CREATE&quot;,</span><br><span class=\"line\">      &quot;ResourceRecordSet&quot;: &#123;</span><br><span class=\"line\">        &quot;Name&quot;: &quot;subdomain.example.com&quot;,</span><br><span class=\"line\">        &quot;Type&quot;: &quot;NS&quot;,</span><br><span class=\"line\">        &quot;TTL&quot;: 300,</span><br><span class=\"line\">        &quot;ResourceRecords&quot;: [</span><br><span class=\"line\">          &#123;</span><br><span class=\"line\">            &quot;Value&quot;: &quot;ns-1.awsdns-1.co.uk&quot;</span><br><span class=\"line\">          &#125;,</span><br><span class=\"line\">          &#123;</span><br><span class=\"line\">            &quot;Value&quot;: &quot;ns-2.awsdns-2.org&quot;</span><br><span class=\"line\">          &#125;,</span><br><span class=\"line\">          &#123;</span><br><span class=\"line\">            &quot;Value&quot;: &quot;ns-3.awsdns-3.com&quot;</span><br><span class=\"line\">          &#125;,</span><br><span class=\"line\">          &#123;</span><br><span class=\"line\">            &quot;Value&quot;: &quot;ns-4.awsdns-4.net&quot;</span><br><span class=\"line\">          &#125;</span><br><span class=\"line\">        ]</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  ]</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<ul>\n<li>Apply the <strong>SUBDOMAIN</strong> NS records to the <strong>PARENT</strong> hosted zone.</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">aws route53 change-resource-record-sets \\</span><br><span class=\"line\"> --hosted-zone-id &lt;parent-zone-id&gt; \\</span><br><span class=\"line\"> --change-batch file://subdomain.json</span><br></pre></td></tr></table></figure>\n<p>Now traffic to <code>*.subdomain.example.com</code> will be routed to the correct subdomain hosted zone in Route53.</p>\n<h3 id=\"Scenario-2-Setting-up-Route53-for-a-domain-purchased-with-another-registrar\"><a href=\"#Scenario-2-Setting-up-Route53-for-a-domain-purchased-with-another-registrar\" class=\"headerlink\" title=\"Scenario 2: Setting up Route53 for a domain purchased with another registrar\"></a>Scenario 2: Setting up Route53 for a domain purchased with another registrar</h3><p>If you bought your domain elsewhere, and would like to dedicate the entire domain to AWS you should follow the guide <a href=\"http://docs.aws.amazon.com/Route53/latest/DeveloperGuide/domain-transfer-to-route-53.html\" target=\"_blank\" rel=\"noopener\">here</a></p>\n<h3 id=\"Scenario-3-Subdomain-for-clusters-in-route53-leaving-the-domain-at-another-registrar\"><a href=\"#Scenario-3-Subdomain-for-clusters-in-route53-leaving-the-domain-at-another-registrar\" class=\"headerlink\" title=\"Scenario 3: Subdomain for clusters in route53, leaving the domain at another registrar\"></a>Scenario 3: Subdomain for clusters in route53, leaving the domain at another registrar</h3><p>If you bought your domain elsewhere, but <strong>only want to use a subdomain in AWS<br>Route53</strong> you must modify your registrar’s NS (NameServer) records.  We’ll create<br>a hosted zone in Route53, and then migrate the subdomain’s NS records to your<br>other registrar.</p>\n<p>You might need to grab <a href=\"https://github.com/stedolan/jq/wiki/Installation\" target=\"_blank\" rel=\"noopener\">jq</a><br>for some of these instructions.</p>\n<ul>\n<li>Create the subdomain, and note your name servers (If you have already done<br>this you can also <a href=\"ns.md\">get the values</a>)</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ID=$(uuidgen) &amp;&amp; aws route53 create-hosted-zone --name subdomain.example.com --<span class=\"built_in\">caller</span>-reference <span class=\"variable\">$ID</span> | jq .DelegationSet.NameServers</span><br></pre></td></tr></table></figure>\n<ul>\n<li><p>You will now go to your registrar’s page and log in. You will need to create a<br>new <strong>SUBDOMAIN</strong>, and use the 4 NS records received from the above command for the new<br><strong>SUBDOMAIN</strong>. This <strong>MUST</strong> be done in order to use your cluster. Do <strong>NOT</strong><br>change your top level NS record, or you might take your site offline.</p>\n</li>\n<li><p>Information on adding NS records with<br><a href=\"https://www.godaddy.com/help/set-custom-nameservers-for-domains-registered-with-godaddy-12317\" target=\"_blank\" rel=\"noopener\">Godaddy.com</a></p>\n</li>\n<li>Information on adding NS records with <a href=\"https://cloud.google.com/dns/update-name-servers\" target=\"_blank\" rel=\"noopener\">Google Cloud<br>Platform</a></li>\n</ul>\n<h4 id=\"Using-Public-Private-DNS-Kops-1-5\"><a href=\"#Using-Public-Private-DNS-Kops-1-5\" class=\"headerlink\" title=\"Using Public/Private DNS (Kops 1.5+)\"></a>Using Public/Private DNS (Kops 1.5+)</h4><p>By default the assumption is that NS records are publically available.  If you<br>require private DNS records you should modify the commands we run later in this<br>guide to include:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kops create cluster --dns private $NAME</span><br></pre></td></tr></table></figure>\n<p>If you have a mix of public and private zones, you will also need to include the <code>--dns-zone</code> argument with the hosted zone id you wish to deploy in:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kops create cluster --dns private --dns-zone ZABCDEFG $NAME</span><br></pre></td></tr></table></figure>\n<h2 id=\"Testing-your-DNS-setup\"><a href=\"#Testing-your-DNS-setup\" class=\"headerlink\" title=\"Testing your DNS setup\"></a>Testing your DNS setup</h2><p>This section is not be required if a gossip-based cluster is created.</p>\n<p>You should now able to dig your domain (or subdomain) and see the AWS Name<br>Servers on the other end.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">dig ns subdomain.example.com</span><br></pre></td></tr></table></figure>\n<p>Should return something similar to:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">;; ANSWER SECTION:</span><br><span class=\"line\">subdomain.example.com.        172800  IN  NS  ns-1.awsdns-1.net.</span><br><span class=\"line\">subdomain.example.com.        172800  IN  NS  ns-2.awsdns-2.org.</span><br><span class=\"line\">subdomain.example.com.        172800  IN  NS  ns-3.awsdns-3.com.</span><br><span class=\"line\">subdomain.example.com.        172800  IN  NS  ns-4.awsdns-4.co.uk.</span><br></pre></td></tr></table></figure>\n<p>This is a critical component of setting up clusters. If you are experiencing<br>problems with the Kubernetes API not coming up, chances are something is wrong<br>with the cluster’s DNS.</p>\n<p><strong>Please DO NOT MOVE ON until you have validated your NS records! This is not be required if a gossip-based cluster is created.</strong></p>\n<h2 id=\"Cluster-State-storage\"><a href=\"#Cluster-State-storage\" class=\"headerlink\" title=\"Cluster State storage\"></a>Cluster State storage</h2><p>In order to store the state of your cluster, and the representation of your<br>cluster, we need to create a dedicated S3 bucket for <code>kops</code> to use.  This<br>bucket will become the source of truth for our cluster configuration.  In<br>this guide we’ll call this bucket <code>example-com-state-store</code>, but you should<br>add a custom prefix as bucket names need to be unique.</p>\n<p>We recommend keeping the creation of this bucket confined to us-east-1,<br>otherwise more work will be required.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">aws s3api create-bucket \\</span><br><span class=\"line\">    --bucket prefix-example-com-state-store \\</span><br><span class=\"line\">    --region us-east-1</span><br></pre></td></tr></table></figure>\n<p>Note: S3 requires <code>--create-bucket-configuration LocationConstraint=&lt;region&gt;</code> for regions other than <code>us-east-1</code>.</p>\n<p>Note: We <strong>STRONGLY</strong> recommend versioning your S3 bucket in case you ever need<br>to revert or recover a previous state store.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">aws s3api put-bucket-versioning --bucket prefix-example-com-state-store  --versioning-configuration Status=Enabled</span><br></pre></td></tr></table></figure>\n<h3 id=\"Sharing-an-S3-bucket-across-multiple-accounts\"><a href=\"#Sharing-an-S3-bucket-across-multiple-accounts\" class=\"headerlink\" title=\"Sharing an S3 bucket across multiple accounts\"></a>Sharing an S3 bucket across multiple accounts</h3><p>It is possible to use a single S3 bucket for storing kops state for clusters<br>located in different accounts, by using <a href=\"http://docs.aws.amazon.com/AmazonS3/latest/dev/example-walkthroughs-managing-access-example2.html#access-policies-walkthrough-cross-account-permissions-acctA-tasks\" target=\"_blank\" rel=\"noopener\">cross-account bucket policies</a>.</p>\n<p>Kops will be able to use buckets configured with cross-account policies by default.</p>\n<p>In this case you may want to override the object ACLs which kops places on the<br>state files, as default AWS ACLs will make it possible for an account that has<br>delegated access to write files that the bucket owner can not read.</p>\n<p>To do this you should set the environment variable <code>KOPS_STATE_S3_ACL</code> to the<br>preferred object ACL, for example <code>bucket-owner-full-control</code>.</p>\n<p>For available canned ACLs please consult <a href=\"http://docs.aws.amazon.com/AmazonS3/latest/dev/acl-overview.html#canned-acl\" target=\"_blank\" rel=\"noopener\">Amazon’s S3<br>documentation</a>.</p>\n<h1 id=\"Creating-your-first-cluster\"><a href=\"#Creating-your-first-cluster\" class=\"headerlink\" title=\"Creating your first cluster\"></a>Creating your first cluster</h1><h2 id=\"Prepare-local-environment\"><a href=\"#Prepare-local-environment\" class=\"headerlink\" title=\"Prepare local environment\"></a>Prepare local environment</h2><p>We’re ready to start creating our first cluster!  Let’s first set up a few<br>environment variables to make this process easier.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">export</span> NAME=myfirstcluster.example.com</span><br><span class=\"line\"><span class=\"built_in\">export</span> KOPS_STATE_STORE=s3://prefix-example-com-state-store</span><br></pre></td></tr></table></figure>\n<p>For a gossip-based cluster, make sure the name ends with <code>k8s.local</code>. For example:</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">export</span> NAME=myfirstcluster.k8s.local</span><br><span class=\"line\"><span class=\"built_in\">export</span> KOPS_STATE_STORE=s3://prefix-example-com-state-store</span><br></pre></td></tr></table></figure>\n<p>Note: You don’t have to use environmental variables here. You can always define<br>the values using the –name and –state flags later.</p>\n<h2 id=\"Create-cluster-configuration\"><a href=\"#Create-cluster-configuration\" class=\"headerlink\" title=\"Create cluster configuration\"></a>Create cluster configuration</h2><p>We will need to note which availability zones are available to us. In this<br>example we will be deploying our cluster to the us-west-2 region.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">aws ec2 describe-availability-zones --region us-west-2</span><br></pre></td></tr></table></figure>\n<p>Below is a create cluster command.  We’ll use the most basic example possible,<br>with more verbose examples in <a href=\"high_availability.md#advanced-example\">high availability</a>.<br>The below command will generate a cluster configuration, but not start building<br>it. Make sure that you have generated SSH key pair before creating the cluster.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kops create cluster \\</span><br><span class=\"line\">    --zones us-west-2a \\</span><br><span class=\"line\">    <span class=\"variable\">$&#123;NAME&#125;</span></span><br></pre></td></tr></table></figure>\n<p>All instances created by <code>kops</code> will be built within ASG (Auto Scaling Groups),<br>which means each instance will be automatically monitored and rebuilt by AWS if<br>it suffers any failure.</p>\n<h2 id=\"Customize-Cluster-Configuration\"><a href=\"#Customize-Cluster-Configuration\" class=\"headerlink\" title=\"Customize Cluster Configuration\"></a>Customize Cluster Configuration</h2><p>Now we have a cluster configuration, we can look at every aspect that defines<br>our cluster by editing the description.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kops edit cluster <span class=\"variable\">$&#123;NAME&#125;</span></span><br></pre></td></tr></table></figure>\n<p>This opens your editor (as defined by $EDITOR) and allows you to edit the<br>configuration.  The configuration is loaded from the S3 bucket we created<br>earlier, and automatically updated when we save and exit the editor.</p>\n<p>We’ll leave everything set to the defaults for now, but the rest of the <code>kops</code><br>documentation covers additional settings and configuration you can enable.</p>\n<h2 id=\"Build-the-Cluster\"><a href=\"#Build-the-Cluster\" class=\"headerlink\" title=\"Build the Cluster\"></a>Build the Cluster</h2><p>Now we take the final step of actually building the cluster.  This’ll take a<br>while.  Once it finishes you’ll have to wait longer while the booted instances<br>finish downloading Kubernetes components and reach a “ready” state.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kops update cluster <span class=\"variable\">$&#123;NAME&#125;</span> --yes</span><br></pre></td></tr></table></figure>\n<h2 id=\"Use-the-Cluster\"><a href=\"#Use-the-Cluster\" class=\"headerlink\" title=\"Use the Cluster\"></a>Use the Cluster</h2><p>Remember when you installed <code>kubectl</code> earlier? The configuration for your<br>cluster was automatically generated and written to <code>~/.kube/config</code> for you!</p>\n<p>A simple Kubernetes API call can be used to check if the API is online and<br>listening. Let’s use <code>kubectl</code> to check the nodes.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kubectl get nodes</span><br></pre></td></tr></table></figure>\n<p>You will see a list of nodes that should match the <code>--zones</code> flag defined<br>earlier. This is a great sign that your Kubernetes cluster is online and<br>working.</p>\n<p>Also <code>kops</code> ships with a handy validation tool that can be ran to ensure your<br>cluster is working as expected.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kops validate cluster</span><br></pre></td></tr></table></figure>\n<p>You can look at all the system components with the following command.</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kubectl -n kube-system get po</span><br></pre></td></tr></table></figure>\n<h2 id=\"Delete-the-Cluster\"><a href=\"#Delete-the-Cluster\" class=\"headerlink\" title=\"Delete the Cluster\"></a>Delete the Cluster</h2><p>Running a Kubernetes cluster within AWS obviously costs money, and so you may<br>want to delete your cluster if you are finished running experiments.</p>\n<p>You can preview all of the AWS resources that will be destroyed when the cluster<br>is deleted by issuing the following command.</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kops delete cluster --name $&#123;NAME&#125;</span><br></pre></td></tr></table></figure>\n<p>When you are sure you want to delete your cluster, issue the delete command<br>with the <code>--yes</code> flag. Note that this command is very destructive, and will<br>delete your cluster and everything contained within it!</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kops delete cluster --name $&#123;NAME&#125; --yes</span><br></pre></td></tr></table></figure>\n<h1 id=\"What’s-next\"><a href=\"#What’s-next\" class=\"headerlink\" title=\"What’s next?\"></a>What’s next?</h1><p>We’ve barely scratched the surface of the capabilities of <code>kops</code> in this guide,<br>and we recommend researching <a href=\"commands.md#other-interesting-modes\">other interesting<br>modes</a> to learn more about generating<br>Terraform configurations, or running your cluster in an HA (Highly Available)<br>mode.</p>\n<p>The <a href=\"cluster_spec.md\">cluster spec docs</a> can help to configure these “other<br>interesting modes”. Also be sure to check out how to run a <a href=\"topology.md\">private network<br>topology</a> in AWS.</p>\n<h2 id=\"Feedback\"><a href=\"#Feedback\" class=\"headerlink\" title=\"Feedback\"></a>Feedback</h2><p>There’s an incredible team behind Kops and we encourage you to reach out to the<br>community on the Kubernetes<br>Slack(<a href=\"http://slack.k8s.io/\" target=\"_blank\" rel=\"noopener\">http://slack.k8s.io/</a>).  Bring your<br>questions, comments, and requests and meet the people behind the project!</p>\n<h2 id=\"Legal\"><a href=\"#Legal\" class=\"headerlink\" title=\"Legal\"></a>Legal</h2><p><em>AWS Trademark used with limited permission under the <a href=\"https://aws.amazon.com/trademark-guidelines/\" target=\"_blank\" rel=\"noopener\">AWS Trademark<br>Guidelines</a></em></p>\n<p><em>Kubernetes Logo used with permission under the <a href=\"https://github.com/kubernetes/kubernetes/blob/master/logo/usage_guidelines.md\" target=\"_blank\" rel=\"noopener\">Kubernetes Branding<br>Guidelines</a></em></p>\n"}],"PostAsset":[],"PostCategory":[{"post_id":"cjbafkkgp000037oh12sl7tsc","category_id":"cjbafmu3g000337ohy2hbt10b","_id":"cjbafmu3h000637ohlprnlnhl"}],"PostTag":[{"post_id":"cjbafkkgp000037oh12sl7tsc","tag_id":"cjbafmu3g000437oh1v7ook5i","_id":"cjbafmu3h000537oh4q2aalr5"},{"post_id":"cjbafkkgp000037oh12sl7tsc","tag_id":"cjbafw2d50000zbohy5ngmmnz","_id":"cjbafw2d80002zbohark42yi7"},{"post_id":"cjbafkkgp000037oh12sl7tsc","tag_id":"cjbafw2d80001zbohl8ner7vq","_id":"cjbafw2d80003zbohu2l9ypem"}],"Tag":[{"name":"k8s, kubernetes","_id":"cjbafkuwr000137ohwm3ndunw"},{"name":"k8s","_id":"cjbafmu3g000437oh1v7ook5i"},{"name":"kubernetes","_id":"cjbafw2d50000zbohy5ngmmnz"},{"name":"docker","_id":"cjbafw2d80001zbohl8ner7vq"}]}}